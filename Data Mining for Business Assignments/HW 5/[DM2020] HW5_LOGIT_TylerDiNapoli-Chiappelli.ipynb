{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up Variable Codings and Data Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Needed Packages\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "import statistics as stat\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#read in the data\n",
    "df = pd.read_csv(r'C:\\Users\\Home\\Documents\\Data Mining\\Assignments\\Assignment 4\\HW4_FlightDelays.csv')\n",
    "\n",
    "#drop \"Weather\" as it is not an ex-ante predictor\n",
    "df.drop('Weather', axis=1, inplace=True)\n",
    "\n",
    "#Group variables into a list based on type (there are no numeric variables in this data set)\n",
    "cvar_list = ['Binned_CRS_DEP_TIME','CARRIER','DEST','ORIGIN','DAY_WEEK','Flight Status']\n",
    "\n",
    "#Creating Dummies for Categorical Variables\n",
    "df2 = df.copy()\n",
    "df2[cvar_list] = df[cvar_list].astype('category')\n",
    "df2 = pd.get_dummies(df2, prefix_sep = '_')\n",
    "\n",
    "#Finding mode of each column so we know what redundant dummy to drop \n",
    "# I am skipping finding the mode for \"flight status\", as I know my event of interest is \"Yes\" and, as such, I will drop the \"No\" equivalents)\n",
    "time_mode = stat.multimode(df['Binned_CRS_DEP_TIME'])\n",
    "carrier_mode = stat.multimode(df['CARRIER'])\n",
    "dest_mode = stat.multimode(df['DEST'])\n",
    "origin_mode = stat.multimode(df['ORIGIN'])\n",
    "day_mode = stat.multimode(df['DAY_WEEK'])\n",
    "\n",
    "delay_rdummy = 'Flight Status_On-time'\n",
    "\n",
    "#remove one \"redundant dummy\", per each set of dummies\n",
    "rdummies = ['Binned_CRS_DEP_TIME_'+str(time_mode[0]), 'CARRIER_'+carrier_mode[0],'DEST_'+dest_mode[0],'ORIGIN_'+origin_mode[0],'DAY_WEEK_'+str(day_mode[0]),delay_rdummy]\n",
    "df3 = df2.copy()\n",
    "df3 = df2.drop(columns=rdummies)\n",
    "\n",
    "#Data Partition:\n",
    "#Splitting the data into our partitions will return two dataframes, so we must prep like so:\n",
    "testpart_size = .2\n",
    "df_partition = df3\n",
    "\n",
    "df_nontestdata, df_testdata = train_test_split(df_partition, test_size = testpart_size, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Over Validation Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              0\n",
      "Binned_CRS_DEP_TIME_1 -0.443884\n",
      "Binned_CRS_DEP_TIME_2 -0.541951\n",
      "Binned_CRS_DEP_TIME_3 -0.644623\n",
      "Binned_CRS_DEP_TIME_4 -0.528231\n",
      "Binned_CRS_DEP_TIME_5  0.317313\n",
      "Binned_CRS_DEP_TIME_7  0.119848\n",
      "Binned_CRS_DEP_TIME_8  0.281964\n",
      "CARRIER_CO             0.450728\n",
      "CARRIER_DL            -0.478140\n",
      "CARRIER_MQ             0.597032\n",
      "CARRIER_OH            -1.028996\n",
      "CARRIER_RU             0.000000\n",
      "CARRIER_UA            -0.007900\n",
      "CARRIER_US            -1.082095\n",
      "DEST_EWR               0.037587\n",
      "DEST_JFK              -0.176243\n",
      "ORIGIN_BWI             0.406243\n",
      "ORIGIN_IAD             0.282862\n",
      "DAY_WEEK_1             0.843737\n",
      "DAY_WEEK_2             0.523882\n",
      "DAY_WEEK_3             0.168618\n",
      "DAY_WEEK_4            -0.161375\n",
      "DAY_WEEK_6            -0.798983\n",
      "DAY_WEEK_7             0.654297\n",
      "Intercept             -0.829062\n",
      "\n",
      " The optimal alpha over the validation partition is 0.4013963963963964\n",
      "The AUC in the validation partition is 0.7211603145996496\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Analysis:\n",
    "DV = 'Flight Status_Delayed'\n",
    "y = df_nontestdata[DV]\n",
    "x = df_nontestdata.drop(columns = [DV])\n",
    "\n",
    "def summary_coef(model_object):\n",
    "    n_predictors = x.shape[1]\n",
    "    model_coef = pd.DataFrame(model_object.coef_.reshape(1,n_predictors),columns = x.columns.values)\n",
    "    model_coef['Intercept'] = model_object.intercept_\n",
    "    return (model_coef.transpose())\n",
    "\n",
    "#Setup Logistic Regression with k-folds = 5\n",
    "kfolds = 5\n",
    "\n",
    "#Establishing alpha range for optimal logistic regression\n",
    "min_alpha = .001\n",
    "max_alpha = 100\n",
    "\n",
    "#Because there are infinite values between min_alpha and max_alpha, we must specify how many alphas Python should look for\n",
    "#Python will then divide that interval into an even number of searches. We need numpy for this\n",
    "n_candidates = 1000\n",
    "alpha_list= list(np.linspace(min_alpha, max_alpha, num = n_candidates))\n",
    "c_list= list(1/np.linspace(min_alpha, max_alpha, num = n_candidates))\n",
    "\n",
    "#Plug in classifier_optimal to our previous Logistic model to find the optimal predictors\n",
    "classifier_optimal = LogisticRegressionCV(Cs = c_list,cv=kfolds,scoring = 'roc_auc',penalty = 'l1',solver='saga',max_iter=2000, random_state=1, n_jobs = -1).fit(x,y)\n",
    "print(summary_coef(classifier_optimal))\n",
    "\n",
    "#Find the optimal selected alpha\n",
    "print('\\n',\"The optimal alpha over the validation partition is\",1/classifier_optimal.C_[0])\n",
    "\n",
    "# Get the AUC of the best model\n",
    "# y_nontest_actual is the actual values of the DV in the validation partition\n",
    "y_nontest_actual = df_nontestdata[DV]\n",
    "# X_nontest is the predictor values in the validation partition\n",
    "X_nontest = df_nontestdata.drop(columns=[DV])\n",
    "\n",
    "print('The AUC in the validation partition is',roc_auc_score(y_nontest_actual, classifier_optimal.predict_proba(X_nontest)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Over Test Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              0\n",
      "Binned_CRS_DEP_TIME_1 -0.403519\n",
      "Binned_CRS_DEP_TIME_2 -0.232250\n",
      "Binned_CRS_DEP_TIME_3 -1.003762\n",
      "Binned_CRS_DEP_TIME_4 -0.486730\n",
      "Binned_CRS_DEP_TIME_5  0.000000\n",
      "Binned_CRS_DEP_TIME_7  0.183454\n",
      "Binned_CRS_DEP_TIME_8  0.000000\n",
      "CARRIER_CO             0.000000\n",
      "CARRIER_DL            -0.676930\n",
      "CARRIER_MQ             0.335434\n",
      "CARRIER_OH            -0.506590\n",
      "CARRIER_RU             0.000000\n",
      "CARRIER_UA             0.000000\n",
      "CARRIER_US            -0.722948\n",
      "DEST_EWR              -0.107451\n",
      "DEST_JFK              -0.105360\n",
      "ORIGIN_BWI             0.713569\n",
      "ORIGIN_IAD             0.687136\n",
      "DAY_WEEK_1             0.328891\n",
      "DAY_WEEK_2             0.000000\n",
      "DAY_WEEK_3            -0.188165\n",
      "DAY_WEEK_4            -0.037408\n",
      "DAY_WEEK_6            -0.829934\n",
      "DAY_WEEK_7             0.796231\n",
      "Intercept             -0.485924\n",
      "\n",
      " The optimal alpha over the test partition is 0.7016936936936937\n",
      "The AUC in the test partition is 0.7265957446808511\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Analysis:\n",
    "DV = 'Flight Status_Delayed'\n",
    "y2 = df_testdata[DV]\n",
    "x2 = df_testdata.drop(columns = [DV])\n",
    "\n",
    "def summary_coef(model_object):\n",
    "    n_predictors = x.shape[1]\n",
    "    model_coef = pd.DataFrame(model_object.coef_.reshape(1,n_predictors),columns = x.columns.values)\n",
    "    model_coef['Intercept'] = model_object.intercept_\n",
    "    return (model_coef.transpose())\n",
    "\n",
    "#Setup Logistic Regression with k-folds = 5\n",
    "kfolds = 5\n",
    "\n",
    "#Establishing alpha range for optimal logistic regression\n",
    "min_alpha = .001\n",
    "max_alpha = 100\n",
    "\n",
    "#Because there are infinite values between min_alpha and max_alpha, we must specify how many alphas Python should look for\n",
    "#Python will then divide that interval into an even number of searches. We need numpy for this\n",
    "n_candidates = 1000\n",
    "alpha_list= list(np.linspace(min_alpha, max_alpha, num = n_candidates))\n",
    "c_list= list(1/np.linspace(min_alpha, max_alpha, num = n_candidates))\n",
    "\n",
    "#Plug in classifier_optimal to our previous Logistic model to find the optimal predictors\n",
    "classifier_optimal2 = LogisticRegressionCV(Cs = c_list,cv=kfolds,scoring = 'roc_auc',penalty = 'l1',solver='saga',max_iter=2000, random_state=1, n_jobs = -1).fit(x2,y2)\n",
    "print(summary_coef(classifier_optimal2))\n",
    "\n",
    "#Find the optimal selected alpha\n",
    "print('\\n',\"The optimal alpha over the test partition is\",1/classifier_optimal2.C_[0])\n",
    "\n",
    "# Get the AUC of the best model\n",
    "# y_nontest_actual is the actual values of the DV in the test partition\n",
    "y_test_actual = df_testdata[DV]\n",
    "# X_nontest is the predictor values in the test partition\n",
    "X_test = df_testdata.drop(columns=[DV])\n",
    "\n",
    "print('The AUC in the test partition is',roc_auc_score(y_test_actual, classifier_optimal2.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
