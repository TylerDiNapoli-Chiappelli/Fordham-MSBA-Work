{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data and Perform Overall Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_reddit_data = pd.read_csv(r'C:\\Users\\Home\\Documents\\Text Analytics\\Group Project\\Raw Data\\correlation.csv')\n",
    "reddit_data = pd.read_csv(r'C:\\Users\\Home\\Documents\\Text Analytics\\Group Project\\Raw Data\\Training-Validation.csv')\n",
    "\n",
    "trimmed_data = reddit_data.append(new_reddit_data, ignore_index = True)\n",
    "\n",
    "\n",
    "trimmed_data.drop(['score', 'url', 'num_comments', 'created'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and clean each post and title and stick the results in lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords = stopwords.words('english')\n",
    "\n",
    "#Tokenize \"body\".\n",
    "tokenized_posts_list = []\n",
    "# Note: word_tokenize() only accepts 1 string at a time. I must loop through the strings and then tokenize it.\n",
    "for i in trimmed_data['body']:\n",
    "    tokens_list = []\n",
    "    tokens = nltk.word_tokenize(str(i))\n",
    "    for j in tokens:\n",
    "        if j.isalpha():\n",
    "            tokens_list.append(j.lower())\n",
    "    tokenized_posts_list.append(tokens_list)\n",
    "    \n",
    "#Tokenize \"title\". \n",
    "tokenized_titles_list = []\n",
    "# Note: word_tokenize() only accepts 1 string at a time. I must loop through the strings and then tokenize it.\n",
    "for i in trimmed_data['title']:\n",
    "    tokens_list = []\n",
    "    tokens = nltk.word_tokenize(str(i))\n",
    "    for j in tokens:\n",
    "        if j.isalpha():\n",
    "            tokens_list.append(j.lower())\n",
    "    tokenized_titles_list.append(tokens_list)\n",
    "\n",
    "#Add list of fully tokenized and cleaned posts onto existing dataframe. This will allow us to analyze each post and count\n",
    "#stuff in order to create our features\n",
    "trimmed_data['Cleaned and Tokenized Titles'] = tokenized_titles_list\n",
    "trimmed_data['Cleaned and Tokenized Posts'] = tokenized_posts_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the \"Gold Standard\" by classifying each subreddit as 1 (likely depression or correlated with depression) or 0 (not likely depression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>body</th>\n",
       "      <th>Cleaned and Tokenized Titles</th>\n",
       "      <th>Cleaned and Tokenized Posts</th>\n",
       "      <th>Manual Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our most-broken and least-understood rules is ...</td>\n",
       "      <td>doqwow</td>\n",
       "      <td>depression</td>\n",
       "      <td>We understand that most people who reply immed...</td>\n",
       "      <td>[our, and, rules, is, helpers, may, not, invit...</td>\n",
       "      <td>[we, understand, that, most, people, who, repl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Regular Check-In Post, with important reminder...</td>\n",
       "      <td>m246c4</td>\n",
       "      <td>depression</td>\n",
       "      <td>Welcome to /r/depression's check-in post - a p...</td>\n",
       "      <td>[regular, post, with, important, reminders, ab...</td>\n",
       "      <td>[welcome, to, post, a, place, to, take, a, mom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I Feel Like I Live In A World Where Evil Wins</td>\n",
       "      <td>m2oac5</td>\n",
       "      <td>depression</td>\n",
       "      <td>Hello  everyone, little short intro here. I am...</td>\n",
       "      <td>[i, feel, like, i, live, in, a, world, where, ...</td>\n",
       "      <td>[hello, everyone, little, short, intro, here, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I just need to tell someone this</td>\n",
       "      <td>m2om39</td>\n",
       "      <td>depression</td>\n",
       "      <td>\\nI’m 17. Today is my Dads 70th birthday.  Tha...</td>\n",
       "      <td>[i, just, need, to, tell, someone, this]</td>\n",
       "      <td>[i, m, today, is, my, dads, birthday, that, mi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im pretty sure i stay up so late because I don...</td>\n",
       "      <td>m2mlcb</td>\n",
       "      <td>depression</td>\n",
       "      <td>I dont know if that makes sense, but thats how...</td>\n",
       "      <td>[im, pretty, sure, i, stay, up, so, late, beca...</td>\n",
       "      <td>[i, dont, know, if, that, makes, sense, but, t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title      id   subreddit  \\\n",
       "0  Our most-broken and least-understood rules is ...  doqwow  depression   \n",
       "1  Regular Check-In Post, with important reminder...  m246c4  depression   \n",
       "2      I Feel Like I Live In A World Where Evil Wins  m2oac5  depression   \n",
       "3                   I just need to tell someone this  m2om39  depression   \n",
       "4  Im pretty sure i stay up so late because I don...  m2mlcb  depression   \n",
       "\n",
       "                                                body  \\\n",
       "0  We understand that most people who reply immed...   \n",
       "1  Welcome to /r/depression's check-in post - a p...   \n",
       "2  Hello  everyone, little short intro here. I am...   \n",
       "3  \\nI’m 17. Today is my Dads 70th birthday.  Tha...   \n",
       "4  I dont know if that makes sense, but thats how...   \n",
       "\n",
       "                        Cleaned and Tokenized Titles  \\\n",
       "0  [our, and, rules, is, helpers, may, not, invit...   \n",
       "1  [regular, post, with, important, reminders, ab...   \n",
       "2  [i, feel, like, i, live, in, a, world, where, ...   \n",
       "3           [i, just, need, to, tell, someone, this]   \n",
       "4  [im, pretty, sure, i, stay, up, so, late, beca...   \n",
       "\n",
       "                         Cleaned and Tokenized Posts  Manual Classification  \n",
       "0  [we, understand, that, most, people, who, repl...                      1  \n",
       "1  [welcome, to, post, a, place, to, take, a, mom...                      1  \n",
       "2  [hello, everyone, little, short, intro, here, ...                      1  \n",
       "3  [i, m, today, is, my, dads, birthday, that, mi...                      1  \n",
       "4  [i, dont, know, if, that, makes, sense, but, t...                      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddits_indicative_of_depression = ['depression','depression_help','mentalhealth','addiction', 'cripplingalcoholism', 'SuicideWatch']\n",
    "\n",
    "manual_classification = []\n",
    "for i in trimmed_data['subreddit']:\n",
    "    \n",
    "    if i in subreddits_indicative_of_depression: \n",
    "        manual_classification.append(1)\n",
    "    else:\n",
    "        manual_classification.append(0)\n",
    "        \n",
    "trimmed_data['Manual Classification'] = manual_classification\n",
    "\n",
    "trimmed_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of the \"Features Grocery Store\" - So we can just go \"shopping\" whenever we need to (meaning create new dataframes with desired features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Psycholinguistic Markers (note: the researchers did not remove stopwords; neither will I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aisle 1: Counts of punctuations and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of Punctuation Characters\n",
    "punctuation = ['~','-',':',';','\"',',','.','?','!']\n",
    "number_of_punctuation_characters = []\n",
    "\n",
    "for i in trimmed_data['body']:\n",
    "    number = 0\n",
    "    for j in punctuation:\n",
    "        number += str(i).count(j)\n",
    "    number_of_punctuation_characters.append(number)\n",
    "\n",
    "#Number of words\n",
    "number_of_words = []\n",
    "\n",
    "for i in trimmed_data['Cleaned and Tokenized Posts']:\n",
    "    number_of_words.append(len(i))\n",
    "    \n",
    "#Number of unique words\n",
    "number_of_unique_words = []\n",
    "\n",
    "for i in trimmed_data['Cleaned and Tokenized Posts']:\n",
    "    number_of_unique_words.append(len(set(i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aisle 2: Parts of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The remaining needed Psycholinguistic Markers are all parts of speech. The first step is to tag the P.O.S once for the whole document\n",
    "#run the P.O.S. tagger on the entire tokenized \"tokenized_posts_list\" list (remember: this is a list of lists)\n",
    "POS_list = []\n",
    "for i in trimmed_data['Cleaned and Tokenized Posts']:\n",
    "    part_of_speech_tags = nltk.pos_tag(i)\n",
    "    POS_list.append(part_of_speech_tags)\n",
    "\n",
    "#Number of Verbs\n",
    "number_of_all_verbs = []\n",
    "for i in POS_list:\n",
    "    all_verbs = [(word,tag) for (word,tag) in i if tag.startswith('V')]\n",
    "    number_of_all_verbs.append(len(all_verbs))\n",
    "    \n",
    "#Number of Adjectives\n",
    "number_of_adjectives = []\n",
    "for i in POS_list:\n",
    "    adjectives = [(word,tag) for (word,tag) in i if tag.startswith('J')]\n",
    "    number_of_adjectives.append(len(adjectives))\n",
    "    \n",
    "#Number of Conjunctions (coordinating conjunctions only)\n",
    "number_of_conjunctions = []\n",
    "for i in POS_list:\n",
    "    conjunctions = [(word,tag) for (word,tag) in i if tag.startswith('CC')]\n",
    "    number_of_conjunctions.append(len(conjunctions))\n",
    "\n",
    "#Number of Prepositions (includes prepositions and subordinating conjunctions)\n",
    "number_of_prepositions = []\n",
    "for i in POS_list:\n",
    "    prepositions = [(word,tag) for (word,tag) in i if tag.startswith('IN')]\n",
    "    number_of_prepositions.append(len(prepositions))\n",
    "    \n",
    "#Number of Infinitives\n",
    "number_of_infinitives = []\n",
    "for i in POS_list:\n",
    "    infinitives = [(word,tag) for (word,tag) in i if tag.endswith('VB')]\n",
    "    number_of_infinitives.append(len(infinitives))\n",
    "    \n",
    "#Number of Past Tense Verbs\n",
    "number_of_past_tense_verbs = []\n",
    "for i in POS_list:\n",
    "    past_tense_verbs = [(word,tag) for (word,tag) in i if tag.startswith('VBD')]\n",
    "    number_of_past_tense_verbs.append(len(past_tense_verbs))\n",
    "    \n",
    "#Number of First Person Verbs (this will be a little inexact; this is the rough combo of VBD and VBP)\n",
    "number_of_first_person_verbs = []\n",
    "for i in POS_list:\n",
    "    first_person_verbs = [(word,tag) for (word,tag) in i if tag.startswith('VBD') or tag.startswith('VBP')]\n",
    "    number_of_first_person_verbs.append(len(first_person_verbs))\n",
    "    \n",
    "#Number of Third-Person Verbs (this will undercount. VBZ is 3rd person singular only; combining with anything else will overcount alot)\n",
    "number_of_third_person_verbs = []\n",
    "for i in POS_list:\n",
    "    third_person_verbs = [(word,tag) for (word,tag) in i if tag.startswith('VBZ')]\n",
    "    number_of_third_person_verbs.append(len(third_person_verbs))\n",
    "    \n",
    "#Number of Pronouns\n",
    "number_of_pronouns = []\n",
    "NLTK_pronouns = ['PRP', 'PRP$', 'WP', 'WP$']\n",
    "for i in POS_list:\n",
    "    pronouns = [(word,tag) for (word,tag) in i if tag in NLTK_pronouns]\n",
    "    number_of_pronouns.append(len(pronouns))\n",
    "    \n",
    "#Number of First-Person Pronouns\n",
    "number_of_first_person_pronouns = []\n",
    "list_of_first_person_pronouns = ['We', 'us', 'our','ourselves', 'I', 'me', 'my', 'mine', 'myself']\n",
    "for i in POS_list:\n",
    "    first_person_pronouns = [(word,tag) for (word,tag) in i if word in list_of_first_person_pronouns]\n",
    "    number_of_first_person_pronouns.append(len(first_person_pronouns))\n",
    "    \n",
    "#Number of Singular First-Person Pronouns\n",
    "number_of_singular_first_person_pronouns = []\n",
    "list_of_singular_first_person_pronouns = ['I', 'me', 'my', 'mine', 'myself']\n",
    "for i in POS_list:\n",
    "    singular_first_person_pronouns = [(word,tag) for (word,tag) in i if word in list_of_singular_first_person_pronouns]\n",
    "    number_of_singular_first_person_pronouns.append(len(singular_first_person_pronouns))\n",
    "    \n",
    "#Number of Plural First-Person Pronouns\n",
    "number_of_plural_first_person_pronouns = []\n",
    "list_of_plural_first_person_pronouns = ['We', 'us', 'our','ourselves']\n",
    "for i in POS_list:\n",
    "    plural_first_person_pronouns = [(word,tag) for (word,tag) in i if word in list_of_plural_first_person_pronouns]\n",
    "    number_of_plural_first_person_pronouns.append(len(plural_first_person_pronouns))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aisle 3: Entire Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because of the non-standard use of punctuation to end sentences, this count is not perfect. But, eyeballing the first 5 entries\n",
    "#it looks good enough\n",
    "number_of_sentences = []\n",
    "for i in trimmed_data['body']:\n",
    "    sentences = nltk.sent_tokenize(str(i))\n",
    "    number_of_sentences.append(len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Paper 1\" Dataframe - The Psycholinguistic Markers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Creation of all needed new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(N punctuation characters) / (N words)\n",
    "punctuation_divided_by_words = [i / j if j > 0 else 'divide by zero' for i, j in zip(number_of_punctuation_characters, number_of_words)]\n",
    "\n",
    "#(N unique words) / (N words)\n",
    "unique_words_divided_by_words = [i / j if j > 0 else 'divide by zero' for i, j in zip(number_of_unique_words, number_of_words)]\n",
    "\n",
    "#(N verbs) / (N adjectives)\n",
    "verbs_divided_by_adjectives = [i / j if j > 0 else 'divide by zero' for i, j in zip(number_of_all_verbs, number_of_adjectives)]\n",
    "\n",
    "#(N conjunctions + N prepositions) / (N sentences)\n",
    "conjunctions_plus_prepositions_divided_by_sentences = [(i + k) / j if j > 0 else 'divide by zero' for i,k,j in zip(number_of_conjunctions, number_of_prepositions, number_of_sentences)]\n",
    "\n",
    "#(N infinitives) / (N verbs)\n",
    "infintives_divided_by_verbs = [i / j if j > 0 else 'divide by zero' for i, j in zip(number_of_infinitives, number_of_all_verbs)]\n",
    "\n",
    "#(N singular first person past tense verbs) / (N verbs) (note: inexactly calculated)\n",
    "SFPPT_verbs_divided_by_verbs = [i / j if j > 0 else 'divide by zero' for i, j in zip(number_of_past_tense_verbs, number_of_all_verbs)]\n",
    "\n",
    "#(N first person verbs) / (N verbs) (inexactly calculated)\n",
    "first_person_verbs_divided_by_verbs = [i / j if j > 0 else 'divide by zero' for i, j in zip(number_of_first_person_verbs, number_of_all_verbs)]\n",
    "\n",
    "#(N third person verbs) / (N verbs) (inexactly calculated)\n",
    "third_person_verbs_divided_by_verbs = [i / j if j > 0 else 'divide by zero' for i, j in zip(number_of_third_person_verbs, number_of_all_verbs)]\n",
    "\n",
    "#(N first person pronouns) / (N pronouns)\n",
    "first_person_pronouns_divided_by_pronouns = [i / j if j > 0 else 'divide by zero' for i, j in zip(number_of_first_person_pronouns, number_of_pronouns)]\n",
    "\n",
    "#(N singular first person pronouns) / (N pronouns)\n",
    "singular_first_person_pronouns_divided_by_pronouns = [i / j if j > 0 else 'divide by zero' for i, j in zip(number_of_singular_first_person_pronouns, number_of_pronouns)]\n",
    "\n",
    "#(N plural first person pronouns) / (N pronouns)\n",
    "plural_first_person_pronouns_divided_by_pronouns = [i / j if j > 0 else 'divide by zero' for i, j in zip(number_of_plural_first_person_pronouns, number_of_pronouns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Creation of \"Dataframe With Psycholinguistic Markers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PM_data = ({'Manual Classification': trimmed_data['Manual Classification'],\n",
    "            'Subreddit': trimmed_data['subreddit'],\n",
    "            'Post Title': trimmed_data['title'], \n",
    "            'Post Body': trimmed_data['body'], \n",
    "            '(N punctuation characters) / (N words)': punctuation_divided_by_words,\n",
    "            '(N unique words) / (N words)': unique_words_divided_by_words,\n",
    "            '(N verbs) / (N adjectives)': verbs_divided_by_adjectives,\n",
    "            '(N conjunctions + N prepositions) / (N sentences)': conjunctions_plus_prepositions_divided_by_sentences,\n",
    "            '(N infinitives) / (N verbs)': infintives_divided_by_verbs,\n",
    "            '(N singular first person past tense verbs) / (N verbs)': SFPPT_verbs_divided_by_verbs,\n",
    "            '(N first person verbs) / (N verbs)': first_person_verbs_divided_by_verbs,\n",
    "            '(N third person verbs) / (N verbs)': third_person_verbs_divided_by_verbs,\n",
    "            '(N first person pronouns) / (N pronouns)': first_person_pronouns_divided_by_pronouns,\n",
    "            '(N singular first person pronouns) / (N pronouns)': singular_first_person_pronouns_divided_by_pronouns,\n",
    "            '(N plural first person pronouns) / (N pronouns)': plural_first_person_pronouns_divided_by_pronouns})\n",
    "\n",
    "PM_dataframe = pd.DataFrame(data = PM_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the purposes of excluding the new data from model training, split the PM_dataframe into two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segregate the new entries into their own dataframe (subreddits: \"addiction\", \"cripplingalcoholism\", and \"SuicideWatch\")\n",
    "new_data_filter = (PM_dataframe['Subreddit'] == 'addiction') | (PM_dataframe['Subreddit'] == 'cripplingalcoholism') | (PM_dataframe['Subreddit'] == 'SuicideWatch')\n",
    "\n",
    "new_data = PM_dataframe.loc[new_data_filter].reset_index(drop = True)\n",
    "\n",
    "PM_dataframe.drop(PM_dataframe[new_data_filter].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manual Classification</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Post Title</th>\n",
       "      <th>Post Body</th>\n",
       "      <th>(N punctuation characters) / (N words)</th>\n",
       "      <th>(N unique words) / (N words)</th>\n",
       "      <th>(N verbs) / (N adjectives)</th>\n",
       "      <th>(N conjunctions + N prepositions) / (N sentences)</th>\n",
       "      <th>(N infinitives) / (N verbs)</th>\n",
       "      <th>(N singular first person past tense verbs) / (N verbs)</th>\n",
       "      <th>(N first person verbs) / (N verbs)</th>\n",
       "      <th>(N third person verbs) / (N verbs)</th>\n",
       "      <th>(N first person pronouns) / (N pronouns)</th>\n",
       "      <th>(N singular first person pronouns) / (N pronouns)</th>\n",
       "      <th>(N plural first person pronouns) / (N pronouns)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>depression</td>\n",
       "      <td>Our most-broken and least-understood rules is ...</td>\n",
       "      <td>We understand that most people who reply immed...</td>\n",
       "      <td>0.133423</td>\n",
       "      <td>0.447439</td>\n",
       "      <td>1.88406</td>\n",
       "      <td>3.594595</td>\n",
       "      <td>0.376923</td>\n",
       "      <td>0.00769231</td>\n",
       "      <td>0.292308</td>\n",
       "      <td>0.169231</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>depression</td>\n",
       "      <td>Regular Check-In Post, with important reminder...</td>\n",
       "      <td>Welcome to /r/depression's check-in post - a p...</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>1.91304</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.0227273</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.159091</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>depression</td>\n",
       "      <td>I Feel Like I Live In A World Where Evil Wins</td>\n",
       "      <td>Hello  everyone, little short intro here. I am...</td>\n",
       "      <td>0.135802</td>\n",
       "      <td>0.510288</td>\n",
       "      <td>2.86364</td>\n",
       "      <td>3.071429</td>\n",
       "      <td>0.206349</td>\n",
       "      <td>0.0952381</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.0952381</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>depression</td>\n",
       "      <td>I just need to tell someone this</td>\n",
       "      <td>\\nI’m 17. Today is my Dads 70th birthday.  Tha...</td>\n",
       "      <td>0.0766129</td>\n",
       "      <td>0.504032</td>\n",
       "      <td>2.29167</td>\n",
       "      <td>2.235294</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0727273</td>\n",
       "      <td>0.309091</td>\n",
       "      <td>0.327273</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>depression</td>\n",
       "      <td>Im pretty sure i stay up so late because I don...</td>\n",
       "      <td>I dont know if that makes sense, but thats how...</td>\n",
       "      <td>0.0833333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>divide by zero</td>\n",
       "      <td>divide by zero</td>\n",
       "      <td>divide by zero</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Manual Classification   Subreddit  \\\n",
       "0                      1  depression   \n",
       "1                      1  depression   \n",
       "2                      1  depression   \n",
       "3                      1  depression   \n",
       "4                      1  depression   \n",
       "\n",
       "                                          Post Title  \\\n",
       "0  Our most-broken and least-understood rules is ...   \n",
       "1  Regular Check-In Post, with important reminder...   \n",
       "2      I Feel Like I Live In A World Where Evil Wins   \n",
       "3                   I just need to tell someone this   \n",
       "4  Im pretty sure i stay up so late because I don...   \n",
       "\n",
       "                                           Post Body  \\\n",
       "0  We understand that most people who reply immed...   \n",
       "1  Welcome to /r/depression's check-in post - a p...   \n",
       "2  Hello  everyone, little short intro here. I am...   \n",
       "3  \\nI’m 17. Today is my Dads 70th birthday.  Tha...   \n",
       "4  I dont know if that makes sense, but thats how...   \n",
       "\n",
       "  (N punctuation characters) / (N words) (N unique words) / (N words)  \\\n",
       "0                               0.133423                     0.447439   \n",
       "1                               0.150943                     0.566038   \n",
       "2                               0.135802                     0.510288   \n",
       "3                              0.0766129                     0.504032   \n",
       "4                              0.0833333                     0.916667   \n",
       "\n",
       "  (N verbs) / (N adjectives)  \\\n",
       "0                    1.88406   \n",
       "1                    1.91304   \n",
       "2                    2.86364   \n",
       "3                    2.29167   \n",
       "4                          2   \n",
       "\n",
       "   (N conjunctions + N prepositions) / (N sentences)  \\\n",
       "0                                           3.594595   \n",
       "1                                           3.600000   \n",
       "2                                           3.071429   \n",
       "3                                           2.235294   \n",
       "4                                           2.000000   \n",
       "\n",
       "  (N infinitives) / (N verbs)  \\\n",
       "0                    0.376923   \n",
       "1                    0.340909   \n",
       "2                    0.206349   \n",
       "3                         0.2   \n",
       "4                           0   \n",
       "\n",
       "  (N singular first person past tense verbs) / (N verbs)  \\\n",
       "0                                         0.00769231       \n",
       "1                                          0.0227273       \n",
       "2                                          0.0952381       \n",
       "3                                          0.0727273       \n",
       "4                                                  0       \n",
       "\n",
       "  (N first person verbs) / (N verbs) (N third person verbs) / (N verbs)  \\\n",
       "0                           0.292308                           0.169231   \n",
       "1                               0.25                           0.159091   \n",
       "2                           0.380952                          0.0952381   \n",
       "3                           0.309091                           0.327273   \n",
       "4                                0.5                                0.5   \n",
       "\n",
       "  (N first person pronouns) / (N pronouns)  \\\n",
       "0                                    0.125   \n",
       "1                                     0.12   \n",
       "2                                 0.444444   \n",
       "3                                 0.393939   \n",
       "4                           divide by zero   \n",
       "\n",
       "  (N singular first person pronouns) / (N pronouns)  \\\n",
       "0                                          0.046875   \n",
       "1                                                 0   \n",
       "2                                          0.111111   \n",
       "3                                          0.393939   \n",
       "4                                    divide by zero   \n",
       "\n",
       "  (N plural first person pronouns) / (N pronouns)  \n",
       "0                                        0.078125  \n",
       "1                                            0.12  \n",
       "2                                        0.333333  \n",
       "3                                               0  \n",
       "4                                  divide by zero  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PM_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manual Classification</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Post Title</th>\n",
       "      <th>Post Body</th>\n",
       "      <th>(N punctuation characters) / (N words)</th>\n",
       "      <th>(N unique words) / (N words)</th>\n",
       "      <th>(N verbs) / (N adjectives)</th>\n",
       "      <th>(N conjunctions + N prepositions) / (N sentences)</th>\n",
       "      <th>(N infinitives) / (N verbs)</th>\n",
       "      <th>(N singular first person past tense verbs) / (N verbs)</th>\n",
       "      <th>(N first person verbs) / (N verbs)</th>\n",
       "      <th>(N third person verbs) / (N verbs)</th>\n",
       "      <th>(N first person pronouns) / (N pronouns)</th>\n",
       "      <th>(N singular first person pronouns) / (N pronouns)</th>\n",
       "      <th>(N plural first person pronouns) / (N pronouns)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>New wiki on how to avoid accidentally encourag...</td>\n",
       "      <td>We've been seeing a worrying increase in pro-s...</td>\n",
       "      <td>0.149872</td>\n",
       "      <td>0.362883</td>\n",
       "      <td>2.15823</td>\n",
       "      <td>2.987805</td>\n",
       "      <td>0.334311</td>\n",
       "      <td>0.0381232</td>\n",
       "      <td>0.237537</td>\n",
       "      <td>0.170088</td>\n",
       "      <td>0.135338</td>\n",
       "      <td>0.0150376</td>\n",
       "      <td>0.120301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>Please remember that NO ACTIVISM of any kind i...</td>\n",
       "      <td>Activism, i.e. advocating or fundraising for s...</td>\n",
       "      <td>0.202247</td>\n",
       "      <td>0.61236</td>\n",
       "      <td>2.07143</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>Love of my life died. Don’t know what to do</td>\n",
       "      <td>\\nI ’m 19 years old and we were going to be to...</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>0.467836</td>\n",
       "      <td>2.82353</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>The repetition is driving me insane. I can't s...</td>\n",
       "      <td>I'm so sick of it. Always tired despite spendi...</td>\n",
       "      <td>0.135802</td>\n",
       "      <td>0.728395</td>\n",
       "      <td>2.66667</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>What’s the point of being alive when you’re poor?</td>\n",
       "      <td>Either go homeless and starve to death or work...</td>\n",
       "      <td>0.0645161</td>\n",
       "      <td>0.752688</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Manual Classification     Subreddit  \\\n",
       "0                      1  SuicideWatch   \n",
       "1                      1  SuicideWatch   \n",
       "2                      1  SuicideWatch   \n",
       "3                      1  SuicideWatch   \n",
       "4                      1  SuicideWatch   \n",
       "\n",
       "                                          Post Title  \\\n",
       "0  New wiki on how to avoid accidentally encourag...   \n",
       "1  Please remember that NO ACTIVISM of any kind i...   \n",
       "2        Love of my life died. Don’t know what to do   \n",
       "3  The repetition is driving me insane. I can't s...   \n",
       "4  What’s the point of being alive when you’re poor?   \n",
       "\n",
       "                                           Post Body  \\\n",
       "0  We've been seeing a worrying increase in pro-s...   \n",
       "1  Activism, i.e. advocating or fundraising for s...   \n",
       "2  \\nI ’m 19 years old and we were going to be to...   \n",
       "3  I'm so sick of it. Always tired despite spendi...   \n",
       "4  Either go homeless and starve to death or work...   \n",
       "\n",
       "  (N punctuation characters) / (N words) (N unique words) / (N words)  \\\n",
       "0                               0.149872                     0.362883   \n",
       "1                               0.202247                      0.61236   \n",
       "2                               0.122807                     0.467836   \n",
       "3                               0.135802                     0.728395   \n",
       "4                              0.0645161                     0.752688   \n",
       "\n",
       "  (N verbs) / (N adjectives)  \\\n",
       "0                    2.15823   \n",
       "1                    2.07143   \n",
       "2                    2.82353   \n",
       "3                    2.66667   \n",
       "4                        2.5   \n",
       "\n",
       "   (N conjunctions + N prepositions) / (N sentences)  \\\n",
       "0                                           2.987805   \n",
       "1                                           3.800000   \n",
       "2                                           1.200000   \n",
       "3                                           2.600000   \n",
       "4                                           2.800000   \n",
       "\n",
       "  (N infinitives) / (N verbs)  \\\n",
       "0                    0.334311   \n",
       "1                    0.206897   \n",
       "2                    0.291667   \n",
       "3                      0.3125   \n",
       "4                         0.4   \n",
       "\n",
       "  (N singular first person past tense verbs) / (N verbs)  \\\n",
       "0                                          0.0381232       \n",
       "1                                           0.137931       \n",
       "2                                           0.166667       \n",
       "3                                             0.0625       \n",
       "4                                                  0       \n",
       "\n",
       "  (N first person verbs) / (N verbs) (N third person verbs) / (N verbs)  \\\n",
       "0                           0.237537                           0.170088   \n",
       "1                           0.206897                           0.344828   \n",
       "2                             0.5625                           0.104167   \n",
       "3                               0.25                             0.0625   \n",
       "4                               0.45                               0.05   \n",
       "\n",
       "  (N first person pronouns) / (N pronouns)  \\\n",
       "0                                 0.135338   \n",
       "1                                 0.363636   \n",
       "2                                     0.25   \n",
       "3                                      0.5   \n",
       "4                                        0   \n",
       "\n",
       "  (N singular first person pronouns) / (N pronouns)  \\\n",
       "0                                         0.0150376   \n",
       "1                                                 0   \n",
       "2                                              0.25   \n",
       "3                                               0.5   \n",
       "4                                                 0   \n",
       "\n",
       "  (N plural first person pronouns) / (N pronouns)  \n",
       "0                                        0.120301  \n",
       "1                                        0.363636  \n",
       "2                                               0  \n",
       "3                                               0  \n",
       "4                                               0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab the Psycholingustic Markers and new_data dataframes and get rid of any row with \"divide by zero\".\n",
    "## Please note that I researched the given warning message and the Python community agrees that it is a bug caused by Numpy and Pandas fighting with each other. It is safe to ignore this warning when conducting this particular operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Psycholinguistic Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Home\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    }
   ],
   "source": [
    "#Copy existing dataframe\n",
    "PM_dataframe_for_ML_models = PM_dataframe.copy()\n",
    "\n",
    "#Drop any row which contains the text string \"divide by zero\"\n",
    "all_columns = list(PM_dataframe_for_ML_models.columns)\n",
    "\n",
    "for i in all_columns:\n",
    "    divide_by_zero_filter = PM_dataframe_for_ML_models[i] == 'divide by zero'\n",
    "    PM_dataframe_for_ML_models.drop(PM_dataframe_for_ML_models[divide_by_zero_filter].index, inplace = True)\n",
    "\n",
    "PM_dataframe_for_ML_models.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy existing dataframe\n",
    "new_data_for_ML_models = new_data.copy()\n",
    "\n",
    "#Drop any row which contains the text string \"divide by zero\"\n",
    "all_columns = list(new_data_for_ML_models.columns)\n",
    "\n",
    "for i in all_columns:\n",
    "    divide_by_zero_filter = new_data_for_ML_models[i] == 'divide by zero'\n",
    "    new_data_for_ML_models.drop(new_data_for_ML_models[divide_by_zero_filter].index, inplace = True)\n",
    "\n",
    "new_data_for_ML_models.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup: Generate Variable List, Standardize Values, and Partition Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Psycholinguistic Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting Up Numerical Variables (there are no categorical variables). Since I create the dataframe in the above code, I can\n",
    "#safely drop 'manual classification', 'subreddit', 'post title', and 'post body' by directly slicing the list by index\n",
    "nvar_list = list(PM_dataframe_for_ML_models.columns)\n",
    "del nvar_list[0:4]\n",
    "\n",
    "#Drop unneeded text columns from dataframe which will be used in Machine Learning models\n",
    "PM_dataframe_for_ML_models.drop(['Subreddit', 'Post Title', 'Post Body'], axis = 1, inplace=True)\n",
    "\n",
    "#Standardizing Numerical variables\n",
    "standardized_PM_dataframe_for_ML_models = PM_dataframe_for_ML_models.copy()\n",
    "\n",
    "original_column_values = PM_dataframe_for_ML_models[nvar_list]\n",
    "sample_mean = PM_dataframe_for_ML_models[nvar_list].mean()\n",
    "sample_stddev = PM_dataframe_for_ML_models[nvar_list].std()\n",
    "\n",
    "standardized_PM_dataframe_for_ML_models[nvar_list] = ((original_column_values - sample_mean)/sample_stddev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Data Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting Up Numerical Variables (there are no categorical variables). Since I create the dataframe in the above code, I can\n",
    "#safely drop 'manual classification', 'subreddit', 'post title', and 'post body' by directly slicing the list by index\n",
    "nvar_list = list(new_data_for_ML_models.columns)\n",
    "del nvar_list[0:4]\n",
    "\n",
    "#Drop unneeded text columns from dataframe which will be used in Machine Learning models\n",
    "new_data_for_ML_models.drop(['Subreddit', 'Post Title', 'Post Body'], axis = 1, inplace=True)\n",
    "\n",
    "#Standardizing Numerical variables\n",
    "standardized_new_data_for_ML_models = new_data_for_ML_models.copy()\n",
    "\n",
    "original_column_values = new_data_for_ML_models[nvar_list]\n",
    "sample_mean = new_data_for_ML_models[nvar_list].mean()\n",
    "sample_stddev = new_data_for_ML_models[nvar_list].std()\n",
    "\n",
    "standardized_new_data_for_ML_models[nvar_list] = ((original_column_values - sample_mean)/sample_stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Partition\n",
    "#Splitting the data into our partitions will return two dataframes, so we must prep like so:\n",
    "test_partition_size = .2\n",
    "data_to_be_partitioned = standardized_PM_dataframe_for_ML_models\n",
    "\n",
    "non_test_data, test_data = train_test_split(data_to_be_partitioned, test_size = test_partition_size, random_state = 1)\n",
    "\n",
    "#use standardized_new_data_for_ML_models in place of existing test data. This way the model will be tested off of subreddits unrelated to training\n",
    "\n",
    "test_data = standardized_new_data_for_ML_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model in the Training/Validation Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                           0\n",
      "(N punctuation characters) / (N words)              0.370752\n",
      "(N unique words) / (N words)                        0.844662\n",
      "(N verbs) / (N adjectives)                         -0.280246\n",
      "(N conjunctions + N prepositions) / (N sentences)   0.111276\n",
      "(N infinitives) / (N verbs)                         0.106644\n",
      "(N singular first person past tense verbs) / (N... -0.878462\n",
      "(N first person verbs) / (N verbs)                  0.140895\n",
      "(N third person verbs) / (N verbs)                 -0.352125\n",
      "(N first person pronouns) / (N pronouns)            0.000000\n",
      "(N singular first person pronouns) / (N pronouns)   1.025793\n",
      "(N plural first person pronouns) / (N pronouns)    -0.204425\n",
      "Intercept                                           0.959950\n",
      "\n",
      "This model's optimal alpha in the validation partition is [1.53831004]\n",
      "The AUC of the optimal model in the validation partition is 0.8762721987674392\n"
     ]
    }
   ],
   "source": [
    "#Establish, for Python's sake, the independent and dependent variables\n",
    "DV = 'Manual Classification'\n",
    "y = non_test_data[DV]\n",
    "x = non_test_data.drop(columns = [DV])\n",
    "\n",
    "#Create Lin Hao's function to return the logistic regression coefficient results in a nice format\n",
    "def summary_coef(model_object):\n",
    "    n_predictors = x.shape[1]\n",
    "    model_coef = pd.DataFrame(model_object.coef_.reshape(1,n_predictors),columns = x.columns.values)\n",
    "    model_coef['Intercept'] = model_object.intercept_\n",
    "    return (model_coef.transpose())\n",
    "\n",
    "#Setup Logistic Regression with k-folds = 5\n",
    "kfolds = 5\n",
    "\n",
    "#Establish alpha range for Python to search within\n",
    "min_alpha = .01\n",
    "max_alpha = 100\n",
    "\n",
    "max_C = 1/min_alpha\n",
    "min_C = 1/max_alpha\n",
    "\n",
    "#Because there are infinite values between min_alpha and max_alpha, we must specify how many alphas Python should look for\n",
    "#Python will then divide that interval into an even number of searches. We need numpy for this\n",
    "n_candidates = 5000\n",
    "c_list= list(np.linspace(min_C, max_C, num = n_candidates))\n",
    "\n",
    "#Run logistic regression, use \"scoring = roc_auc\" to get the Area Under the Curve, and send it into the \"nice formatting\" function\n",
    "classifier_optimal = LogisticRegressionCV(Cs = c_list, cv=kfolds, scoring = 'roc_auc', penalty = 'l1',solver='saga',max_iter=200, random_state=1, n_jobs = -1).fit(x,y)\n",
    "print(summary_coef(classifier_optimal))\n",
    "\n",
    "#Find the optimal selected alpha\n",
    "print(\"\\nThis model's optimal alpha in the validation partition is\",1/classifier_optimal.C_)\n",
    "\n",
    "# predict probabilities\n",
    "logistic_regression_predicted_probabilities_validation_partition = classifier_optimal.predict_proba(x)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "logistic_regression_predicted_probabilities_validation_partition = logistic_regression_predicted_probabilities_validation_partition[:, 1]\n",
    "\n",
    "# calculate AUC\n",
    "AUC_logistic_regression_validation_partition = roc_auc_score(y, logistic_regression_predicted_probabilities_validation_partition)\n",
    "print('The AUC of the optimal model in the validation partition is', AUC_logistic_regression_validation_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model in the Test Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                           0\n",
      "(N punctuation characters) / (N words)              0.357888\n",
      "(N unique words) / (N words)                        0.834146\n",
      "(N verbs) / (N adjectives)                         -0.275073\n",
      "(N conjunctions + N prepositions) / (N sentences)   0.102943\n",
      "(N infinitives) / (N verbs)                         0.091333\n",
      "(N singular first person past tense verbs) / (N... -0.864351\n",
      "(N first person verbs) / (N verbs)                  0.117717\n",
      "(N third person verbs) / (N verbs)                 -0.353645\n",
      "(N first person pronouns) / (N pronouns)            0.000000\n",
      "(N singular first person pronouns) / (N pronouns)   1.015815\n",
      "(N plural first person pronouns) / (N pronouns)    -0.199772\n",
      "Intercept                                           0.951465\n",
      "\n",
      "This model's optimal alpha in the test partition is [3.99961596]\n"
     ]
    }
   ],
   "source": [
    "#Establish, for Python's sake, the independent and dependent variables\n",
    "DV = 'Manual Classification'\n",
    "y2 = test_data[DV]\n",
    "x2 = test_data.drop(columns = [DV])\n",
    "\n",
    "#Run logistic regression, use \"scoring = roc_auc\" to get the Area Under the Curve, and send it into the \"nice formatting\" function\n",
    "classifier_optimal_2 = LogisticRegressionCV(Cs = c_list, cv=kfolds, penalty = 'l1',solver='saga',max_iter=200, random_state=1, n_jobs = -1).fit(x,y)\n",
    "print(summary_coef(classifier_optimal_2))\n",
    "\n",
    "#Find the optimal selected alpha\n",
    "print(\"\\nThis model's optimal alpha in the test partition is\",1/classifier_optimal_2.C_)\n",
    "\n",
    "# predict probabilities\n",
    "logistic_regression_predicted_probabilities_test_partition = classifier_optimal_2.predict_proba(x2)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "logistic_regression_predicted_probabilities_test_partition = logistic_regression_predicted_probabilities_test_partition[:, 1]\n",
    "\n",
    "# calculate AUC\n",
    "# AUC_logistic_regression_test_partition = roc_auc_score(y2, logistic_regression_predicted_probabilities_test_partition)\n",
    "# print('The AUC of the optimal model in the test partition is', AUC_logistic_regression_test_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Confusion Matrix (validation partition)\n",
    "\n",
    "#### Note: since we are dealing with flagging depression, we are most concerned with capturing all True Positives and avoiding False Negatives, since we want to help people to are depressed (capture True Positives) and avoid accidentally ignoring people who are depressed (avoid False Negatives). Thus, we want to measure positive precision and positive recall together as the F-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The positive precision for the logistic regression model in the test partition is 1.0\n",
      "The positive recall for the logistic regression model in the test partition is 0.7151187005414411\n",
      "The F-score for the logistic regression model in the test partition is 0.8338999514327343\n"
     ]
    }
   ],
   "source": [
    "#convert predicted probabilties into 1s and 0s\n",
    "y_predicted_logistic_regression = []\n",
    "for i in logistic_regression_predicted_probabilities_test_partition:\n",
    "    if i >= .5:\n",
    "        y_predicted_logistic_regression.append(1)\n",
    "    else:\n",
    "        y_predicted_logistic_regression.append(0)\n",
    "        \n",
    "#create confusion matrix: confusion_matrix(y_true, y_pred)\n",
    "#Note from sci-k itlearn.org:\n",
    "#Thus in binary classification, the count of true negatives is M[0,0], false negatives is M[1,0], \n",
    "    #true positives is M[1,1], and false positives is M[0,1].\n",
    "logistic_regression_confusion_matrix = confusion_matrix(y2, y_predicted_logistic_regression)\n",
    "\n",
    "logistic_regression_true_positive = logistic_regression_confusion_matrix[1,1]\n",
    "logistic_regression_true_negative = logistic_regression_confusion_matrix[0,0]\n",
    "logistic_regression_false_positive = logistic_regression_confusion_matrix[0,1]\n",
    "logistic_regression_false_negative = logistic_regression_confusion_matrix[1,0]\n",
    "\n",
    "#Calculate positive precision\n",
    "logistic_regression_positive_precision = logistic_regression_true_positive / (logistic_regression_true_positive + logistic_regression_false_positive)\n",
    "print('The positive precision for the logistic regression model in the test partition is',logistic_regression_positive_precision)\n",
    "\n",
    "#Calculate positive recall\n",
    "logistic_regression_positive_recall = logistic_regression_true_positive / (logistic_regression_true_positive + logistic_regression_false_negative)\n",
    "print('The positive recall for the logistic regression model in the test partition is',logistic_regression_positive_recall)\n",
    "\n",
    "#Calculate F score\n",
    "logistic_regression_F_score = (2 * logistic_regression_positive_precision * logistic_regression_positive_recall) / (logistic_regression_positive_precision + logistic_regression_positive_recall)\n",
    "print('The F-score for the logistic regression model in the test partition is',logistic_regression_F_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model in the Training/Validation Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal k in the validation partition is 99\n",
      "The AUC of the optimal model in the validation partition is 0.8915001437163503\n"
     ]
    }
   ],
   "source": [
    "#Establish, for Python's sake, the independent and dependent variables\n",
    "DV = 'Manual Classification'\n",
    "y = non_test_data[DV]\n",
    "x = non_test_data.drop(columns = [DV])\n",
    "\n",
    "# Run Nearest Neighbors with k-fold cross validation with k=5\n",
    "kfolds = 5\n",
    "\n",
    "# Here we specify within which range of Ks we will search through and save that range into a dictionary\n",
    "max_k = 200\n",
    "parameters_grid = {'n_neighbors': list(range(1, max_k + 1))}\n",
    "\n",
    "#Setup a k-NN model which will search through all of our specified hyperparameters (the ks) and then apply the model to our data\n",
    "k_NN = GridSearchCV(KNeighborsClassifier(metric = 'euclidean'), parameters_grid, scoring='roc_auc', cv=kfolds, n_jobs=-1)\n",
    "k_NN.fit(x,y)\n",
    "classifier_best_KNN = k_NN.best_estimator_\n",
    "\n",
    "# Display optimal k\n",
    "print('The optimal k in the validation partition is',classifier_best_KNN.n_neighbors)\n",
    "\n",
    "# predict probabilities\n",
    "k_NN_predicted_probabilities_validation_partition = classifier_best_KNN.predict_proba(x)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "k_NN_predicted_probabilities_validation_partition = k_NN_predicted_probabilities_validation_partition[:, 1]\n",
    "\n",
    "# calculate AUC\n",
    "AUC_k_NN_validation_partition = roc_auc_score(y, k_NN_predicted_probabilities_validation_partition)\n",
    "print('The AUC of the optimal model in the validation partition is', AUC_k_NN_validation_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model in the Test Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal k in the test partition is 49\n"
     ]
    }
   ],
   "source": [
    "#Establish, for Python's sake, the independent and dependent variables\n",
    "DV = 'Manual Classification'\n",
    "y2 = test_data[DV]\n",
    "x2 = test_data.drop(columns = [DV])\n",
    "\n",
    "#Setup a k-NN model which will search through all of our specified hyperparameters (the ks) and then apply the model to our data\n",
    "k_NN_2 = GridSearchCV(KNeighborsClassifier(metric = 'euclidean'), parameters_grid, cv=kfolds, n_jobs=-1)\n",
    "k_NN_2.fit(x,y)\n",
    "classifier_best_KNN_2 = k_NN_2.best_estimator_\n",
    "\n",
    "# Display optimal k\n",
    "print('The optimal k in the test partition is',classifier_best_KNN_2.n_neighbors)\n",
    "\n",
    "#predict probabilities\n",
    "k_NN_predicted_probabilities_test_partition = classifier_best_KNN_2.predict_proba(x2)\n",
    "\n",
    "#keep probabilities for the positive outcome only\n",
    "k_NN_predicted_probabilities_test_partition = k_NN_predicted_probabilities_test_partition[:, 1]\n",
    "\n",
    "# calculate AUC\n",
    "# AUC_k_NN_test_partition = roc_auc_score(y2, k_NN_predicted_probabilities_test_partition)\n",
    "# print('The AUC of the optimal model in the test partition is', AUC_k_NN_test_partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN Confusion Matrix (test partition)\n",
    "\n",
    "#### Note: since we are dealing with flagging depression, we are most concerned with capturing all True Positives and avoiding False Negatives, since we want to help people to are depressed (capture True Positives) and avoid accidentally ignoring people who are depressed (avoid False Negatives). Thus, we want to measure positive precision and positive recall together as the F-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The positive precision for the k-NN model in the test partition is 1.0\n",
      "The positive recall for the k-NN model in the test partition is 0.7067888379841732\n",
      "The F-score for the k-NN model in the test partition is 0.8282088823816496\n",
      "The model's accuracy against the test partition is 0.7067888379841732\n",
      "The F-score for the k-NN model in the test partition is 0.8282088823816496\n"
     ]
    }
   ],
   "source": [
    "#convert predicted probabilties into 1s and 0s\n",
    "y_predicted_k_NN = []\n",
    "for i in k_NN_predicted_probabilities_test_partition:\n",
    "    if i >= .5:\n",
    "        y_predicted_k_NN.append(1)\n",
    "    else:\n",
    "        y_predicted_k_NN.append(0)\n",
    "        \n",
    "# create confusion matrix: confusion_matrix(y_true, y_pred)\n",
    "# Note from sci-k itlearn.org:\n",
    "# Thus in binary classification, the count of true negatives is M[0,0], false negatives is M[1,0], \n",
    "#     true positives is M[1,1], and false positives is M[0,1].\n",
    "k_NN_confusion_matrix = confusion_matrix(y2,y_predicted_k_NN)\n",
    "\n",
    "k_NN_true_positive = k_NN_confusion_matrix[1,1]\n",
    "k_NN_true_negative = k_NN_confusion_matrix[0,0]\n",
    "k_NN_false_positive = k_NN_confusion_matrix[0,1]\n",
    "k_NN_false_negative = k_NN_confusion_matrix[1,0]\n",
    "\n",
    "#Calculate positive precision\n",
    "k_NN_positive_precision = k_NN_true_positive / (k_NN_true_positive + k_NN_false_positive)\n",
    "print('The positive precision for the k-NN model in the test partition is',k_NN_positive_precision)\n",
    "\n",
    "#Calculate positive recall\n",
    "k_NN_positive_recall = k_NN_true_positive / (k_NN_true_positive + k_NN_false_negative)\n",
    "print('The positive recall for the k-NN model in the test partition is',k_NN_positive_recall)\n",
    "\n",
    "#Calculate F score\n",
    "k_NN_F_score = (2 * k_NN_positive_precision * k_NN_positive_recall) / (k_NN_positive_precision + k_NN_positive_recall)\n",
    "print('The F-score for the k-NN model in the test partition is',k_NN_F_score)\n",
    "\n",
    "#Calculate accuracy rate\n",
    "print(\"The model's accuracy against the test partition is\",classifier_best_KNN_2.score(x2,y2))\n",
    "\n",
    "#Calculate F score\n",
    "k_NN_F_score = (2 * k_NN_positive_precision * k_NN_positive_recall) / (k_NN_positive_precision + k_NN_positive_recall)\n",
    "print('The F-score for the k-NN model in the test partition is',k_NN_F_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Tree (data standardization does not matter, though our data is already standardized at this point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model in the Validation Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best pruned tree in the validation partition is of depth 5\n",
      "The AUC of the best pruned tree in the validation partition is 0.8904330884489143\n"
     ]
    }
   ],
   "source": [
    "#Establish, for Python's sake, the independent and dependent variables\n",
    "DV = 'Manual Classification'\n",
    "y = non_test_data[DV]\n",
    "x = non_test_data.drop(columns = [DV])\n",
    "\n",
    "# Run Classification tree with k-fold cross validation with k=5\n",
    "kfolds = 5\n",
    "\n",
    "# Here we specify within which range of depths we will search for the best pruned tree\n",
    "maximum_depth = 100\n",
    "minimum_depth = 1\n",
    "parameter_grid = {'max_depth': list(range(minimum_depth, maximum_depth + 1))}\n",
    "\n",
    "classification_tree = GridSearchCV(DecisionTreeClassifier(criterion='entropy', random_state=1), parameter_grid, scoring='roc_auc', cv=kfolds, n_jobs=-1)\n",
    "classification_tree.fit(x,y)\n",
    "best_pruned_tree = classification_tree.best_estimator_\n",
    "\n",
    "# Display the level of depth of the best pruned tree\n",
    "print('The best pruned tree in the validation partition is of depth',best_pruned_tree.get_depth())\n",
    "\n",
    "# predict probabilities\n",
    "classification_tree_predicted_probabilities_validation_partition = best_pruned_tree.predict_proba(x)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "classification_tree_predicted_probabilities_validation_partition = classification_tree_predicted_probabilities_validation_partition[:, 1]\n",
    "\n",
    "# calculate AUC\n",
    "AUC_classification_tree_validation_partition = roc_auc_score(y, classification_tree_predicted_probabilities_validation_partition)\n",
    "print('The AUC of the best pruned tree in the validation partition is', AUC_classification_tree_validation_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model in the Test Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best pruned tree in the test partition is of depth 4\n"
     ]
    }
   ],
   "source": [
    "#Establish, for Python's sake, the independent and dependent variables\n",
    "DV = 'Manual Classification'\n",
    "y2 = test_data[DV]\n",
    "x2 = test_data.drop(columns = [DV])\n",
    "\n",
    "# Run Classification tree with k-fold cross test with k=5\n",
    "kfolds = 5\n",
    "\n",
    "# Here we specify within which range of depths we will search for the best pruned tree\n",
    "maximum_depth = 100\n",
    "minimum_depth = 1\n",
    "parameter_grid = {'max_depth': list(range(minimum_depth, maximum_depth + 1))}\n",
    "\n",
    "classification_tree_2 = GridSearchCV(DecisionTreeClassifier(criterion='entropy', random_state=1), parameter_grid, cv=kfolds, n_jobs=-1)\n",
    "classification_tree_2.fit(x,y)\n",
    "best_pruned_tree_2 = classification_tree_2.best_estimator_\n",
    "\n",
    "# Display the level of depth of the best pruned tree\n",
    "print('The best pruned tree in the test partition is of depth',best_pruned_tree_2.get_depth())\n",
    "\n",
    "# predict 1s and 0s\n",
    "classification_tree_predicted_probabilities_test_partition = best_pruned_tree_2.predict_proba(x2)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "classification_tree_predicted_probabilities_test_partition = classification_tree_predicted_probabilities_test_partition[:, 1]\n",
    "\n",
    "# # calculate AUC\n",
    "# AUC_classification_tree_test_partition = roc_auc_score(y2, classification_tree_predicted_probabilities_test_partition)\n",
    "# print('The AUC of the best pruned tree in the test partition is', AUC_classification_tree_test_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Tree Confusion Matrix (test partition)\n",
    "\n",
    "#### Note: since we are dealing with flagging depression, we are most concerned with capturing all True Positives and avoiding False Negatives, since we want to help people to are depressed (capture True Positives) and avoid accidentally ignoring people who are depressed (avoid False Negatives). Thus, we want to measure positive precision and positive recall together as the F-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The positive precision for the classification tree model in the test partition is 1.0\n",
      "The positive recall for the classification tree model in the test partition is 0.7784256559766763\n",
      "The F-score for the classification tree model in the test partition is 0.8754098360655737\n",
      "The model's accuracy against the test partition is 0.7784256559766763\n",
      "The F-score for the classification tree model in the test partition is 0.8754098360655737\n"
     ]
    }
   ],
   "source": [
    "#convert predicted probabilties into 1s and 0s\n",
    "y_predicted_classification_tree = []\n",
    "for i in classification_tree_predicted_probabilities_test_partition:\n",
    "    if i >= .5:\n",
    "        y_predicted_classification_tree.append(1)\n",
    "    else:\n",
    "        y_predicted_classification_tree.append(0)\n",
    "        \n",
    "# create confusion matrix: confusion_matrix(y_true, y_pred)\n",
    "# Note from sci-k itlearn.org:\n",
    "# Thus in binary classification, the count of true negatives is M[0,0], false negatives is M[1,0], \n",
    "    #true positives is M[1,1], and false positives is M[0,1].\n",
    "classification_tree_confusion_matrix = confusion_matrix(y2,y_predicted_classification_tree)\n",
    "\n",
    "classification_tree_true_positive = classification_tree_confusion_matrix[1,1]\n",
    "classification_tree_true_negative = classification_tree_confusion_matrix[0,0]\n",
    "classification_tree_false_positive = classification_tree_confusion_matrix[0,1]\n",
    "classification_tree_false_negative = classification_tree_confusion_matrix[1,0]\n",
    "\n",
    "#Calculate positive precision\n",
    "classification_tree_positive_precision = classification_tree_true_positive / (classification_tree_true_positive + classification_tree_false_positive)\n",
    "print('The positive precision for the classification tree model in the test partition is',classification_tree_positive_precision)\n",
    "\n",
    "#Calculate positive recall\n",
    "classification_tree_positive_recall = classification_tree_true_positive / (classification_tree_true_positive + classification_tree_false_negative)\n",
    "print('The positive recall for the classification tree model in the test partition is',classification_tree_positive_recall)\n",
    "\n",
    "#Calculate F score\n",
    "classification_tree_F_score = (2 * classification_tree_positive_precision * classification_tree_positive_recall) / (classification_tree_positive_precision + classification_tree_positive_recall)\n",
    "print('The F-score for the classification tree model in the test partition is',classification_tree_F_score)\n",
    "\n",
    "#Calculate accuracy rate\n",
    "print(\"The model's accuracy against the test partition is\",best_pruned_tree_2.score(x2,y2))\n",
    "\n",
    "#Calculate F score\n",
    "classification_tree_F_score = (2 * classification_tree_positive_precision * classification_tree_positive_recall) / (classification_tree_positive_precision + classification_tree_positive_recall)\n",
    "print('The F-score for the classification tree model in the test partition is',classification_tree_F_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model in the validation partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC for the random forest model in the validation partition is 0.9854008140835842\n"
     ]
    }
   ],
   "source": [
    "#Establish, for Python's sake, the independent and dependent variables\n",
    "DV = 'Manual Classification'\n",
    "y = non_test_data[DV]\n",
    "x = non_test_data.drop(columns = [DV])\n",
    "\n",
    "# Run Random Forest with k-fold cross validation with k=5\n",
    "kfolds = 5\n",
    "\n",
    "#Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 3)]\n",
    "\n",
    "#Number of features to consider at every split\n",
    "#From the Random Forest Python documentation: \n",
    "    #Empirical good default values are max_features=sqrt(n_features) for classification tasks\n",
    "    #This translates to the 'sqrt' default option that the model contains\n",
    "max_features = ['sqrt']\n",
    "\n",
    "#Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 3)]\n",
    "max_depth.append(None)\n",
    "\n",
    "#Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "#Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "#Create the random grid, and run the classifier on our x and y\n",
    "param_grid = {'n_estimators': n_estimators,'max_features': max_features,'max_depth': max_depth,\n",
    "              'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "grid_cv = GridSearchCV(rf, param_grid, scoring = 'roc_auc', cv = kfolds, n_jobs=-1)\n",
    "grid_cv.fit(x, y)\n",
    "\n",
    "random_forest_classifier_optimal_validation_partition = grid_cv.best_estimator_\n",
    "\n",
    "# predict probabilities using the classifier and keep probabilities for the positive outcome only\n",
    "random_forest_predicted_probabilities_validation_partition = random_forest_classifier_optimal_validation_partition.predict_proba(x)[:,1]\n",
    "\n",
    "# Get the AUC of the best Random Forest Classifier\n",
    "AUC_random_forest_validation_partition = roc_auc_score(y, random_forest_predicted_probabilities_validation_partition)\n",
    "print('The AUC for the random forest model in the validation partition is', AUC_random_forest_validation_partition )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model in the test partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establish, for Python's sake, the independent and dependent variables\n",
    "DV = 'Manual Classification'\n",
    "y2 = test_data[DV]\n",
    "x2 = test_data.drop(columns = [DV])\n",
    "\n",
    "# Run Random Forest with k-fold cross test with k=5\n",
    "kfolds = 5\n",
    "\n",
    "#Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 3)]\n",
    "\n",
    "#Number of features to consider at every split\n",
    "#From the Random Forest Python documentation: \n",
    "    #Empirical good default values are max_features=sqrt(n_features) for classification tasks\n",
    "    #This translates to the 'sqrt' default option that the model contains\n",
    "max_features = ['sqrt']\n",
    "\n",
    "#Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 3)]\n",
    "max_depth.append(None)\n",
    "\n",
    "#Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "#Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "#Create the random grid, and run the classifier on our x and y\n",
    "param_grid = {'n_estimators': n_estimators,'max_features': max_features,'max_depth': max_depth,\n",
    "              'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "grid_cv = GridSearchCV(rf, param_grid, cv = kfolds, n_jobs=-1)\n",
    "grid_cv.fit(x, y)\n",
    "\n",
    "random_forest_classifier_optimal_test_partition = grid_cv.best_estimator_\n",
    "\n",
    "# predict probabilities and keep only positive outcomes\n",
    "random_forest_predicted_probabilities_test_partition = random_forest_classifier_optimal_test_partition.predict_proba(x2)[:,1]\n",
    "\n",
    "#Get the AUC of the best Random Forest Classifier\n",
    "# AUC_random_forest_test_partition = roc_auc_score(y2, random_forest_predicted_probabilities_test_partition)\n",
    "# print('The AUC for the random forest model in the test partition is', AUC_random_forest_test_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Confusion Matrix (test partition)\n",
    "\n",
    "#### Note: since we are dealing with flagging depression, we are most concerned with capturing all True Positives and avoiding False Negatives, since we want to help people to are depressed (capture True Positives) and avoid accidentally ignoring people who are depressed (avoid False Negatives). Thus, we want to measure positive precision and positive recall together as the F-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The positive precision for the random forest model in the test partition is 1.0\n",
      "The positive recall for the random forest model in the test partition is 0.7317784256559767\n",
      "The F-score for the random forest model in the test partition is 0.8451178451178452\n",
      "The model's accuracy against the test partition is 0.7317784256559767\n",
      "The F-score for the random forest model in the test partition is 0.8451178451178452\n"
     ]
    }
   ],
   "source": [
    "#convert predicted probabilties into 1s and 0s\n",
    "y_predicted_random_forest = []\n",
    "for i in random_forest_predicted_probabilities_test_partition:\n",
    "    if i >= .5:\n",
    "        y_predicted_random_forest.append(1)\n",
    "    else:\n",
    "        y_predicted_random_forest.append(0)\n",
    "        \n",
    "# create confusion matrix: confusion_matrix(y_true, y_pred)\n",
    "# Note from sci-k itlearn.org:\n",
    "# Thus in binary classification, the count of true negatives is M[0,0], false negatives is M[1,0], \n",
    "#     true positives is M[1,1], and false positives is M[0,1].\n",
    "random_forest_confusion_matrix = confusion_matrix(y2,y_predicted_random_forest)\n",
    "\n",
    "random_forest_true_positive = random_forest_confusion_matrix[1,1]\n",
    "random_forest_true_negative = random_forest_confusion_matrix[0,0]\n",
    "random_forest_false_positive = random_forest_confusion_matrix[0,1]\n",
    "random_forest_false_negative = random_forest_confusion_matrix[1,0]\n",
    "\n",
    "#Calculate positive precision\n",
    "random_forest_positive_precision = random_forest_true_positive / (random_forest_true_positive + random_forest_false_positive)\n",
    "print('The positive precision for the random forest model in the test partition is',random_forest_positive_precision)\n",
    "\n",
    "#Calculate positive recall\n",
    "random_forest_positive_recall = random_forest_true_positive / (random_forest_true_positive + random_forest_false_negative)\n",
    "print('The positive recall for the random forest model in the test partition is',random_forest_positive_recall)\n",
    "\n",
    "#Calculate F score\n",
    "random_forest_F_score = (2 * random_forest_positive_precision * random_forest_positive_recall) / (random_forest_positive_precision + random_forest_positive_recall)\n",
    "print('The F-score for the random forest model in the test partition is',random_forest_F_score)\n",
    "\n",
    "#Calculate accuracy rate\n",
    "print(\"The model's accuracy against the test partition is\",random_forest_classifier_optimal_test_partition.score(x2,y2))\n",
    "\n",
    "#Calculate F score\n",
    "random_forest_F_score = (2 * random_forest_positive_precision * random_forest_positive_recall) / (random_forest_positive_precision + random_forest_positive_recall)\n",
    "print('The F-score for the random forest model in the test partition is',random_forest_F_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model in the validation partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC for the adaboost model in the validation partition is 1.0\n"
     ]
    }
   ],
   "source": [
    "#Establish, for Python's sake, the independent and dependent variables\n",
    "DV = 'Manual Classification'\n",
    "y = non_test_data[DV]\n",
    "x = non_test_data.drop(columns = [DV])\n",
    "\n",
    "# Run Random Forest with k-fold cross validation with k=5\n",
    "kfolds = 5\n",
    "\n",
    "#Set a parameter grid for the GridSearchCV\n",
    "param_grid = {\"base_estimator__criterion\": [\"gini\", \"entropy\"], \"base_estimator__splitter\": [\"best\", \"random\"], \n",
    "              \"n_estimators\": [10, 50, 100, 500]}\n",
    "\n",
    "#Assigning models and functions\n",
    "DTC = DecisionTreeClassifier(random_state = 1, max_features = \"auto\", max_depth = 10)\n",
    "adaboost = AdaBoostClassifier(base_estimator = DTC, random_state=1)\n",
    "\n",
    "#Use a GridSearchCV to find the optimal model candidate\n",
    "grid_cv = GridSearchCV(adaboost, param_grid, scoring = 'roc_auc', cv = kfolds, n_jobs=-1)\n",
    "grid_cv.fit(x, y)\n",
    "adaboost_classifier_optimal_validation_partition = grid_cv.best_estimator_\n",
    "\n",
    "# predict probabilities using the classifier and keep probabilities for the positive outcome only\n",
    "adaboost_predicted_probabilities_validation_partition = adaboost_classifier_optimal_validation_partition.predict_proba(x)[:,1]\n",
    "\n",
    "# Get the AUC in the validation partition\n",
    "AUC_adaboost_validation_partition = roc_auc_score(y, adaboost_predicted_probabilities_validation_partition)\n",
    "print('The AUC for the adaboost model in the validation partition is', AUC_adaboost_validation_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model in the test partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establish, for Python's sake, the independent and dependent variables\n",
    "DV = 'Manual Classification'\n",
    "y2 = test_data[DV]\n",
    "x2 = test_data.drop(columns = [DV])\n",
    "\n",
    "# Run Random Forest with k-fold cross test with k=5\n",
    "kfolds = 5\n",
    "\n",
    "#Set a parameter grid for the GridSearchCV\n",
    "param_grid = {\"base_estimator__criterion\": [\"gini\", \"entropy\"], \"base_estimator__splitter\": [\"best\", \"random\"], \n",
    "              \"n_estimators\": [10, 50, 100, 500]}\n",
    "\n",
    "#Assigning models and functions\n",
    "DTC = DecisionTreeClassifier(random_state = 1, max_features = \"auto\", max_depth = 10)\n",
    "adaboost = AdaBoostClassifier(base_estimator = DTC, random_state=1)\n",
    "\n",
    "#Use a GridSearchCV to find the optimal model candidate\n",
    "grid_cv = GridSearchCV(adaboost, param_grid, cv = kfolds, n_jobs=-1)\n",
    "grid_cv.fit(x, y)\n",
    "adaboost_classifier_optimal_test_partition = grid_cv.best_estimator_\n",
    "\n",
    "# predict probabilities and keep only predictions for the positive outcome\n",
    "adaboost_predicted_probabilities_test_partition = adaboost_classifier_optimal_test_partition.predict_proba(x2)[:,1]\n",
    "\n",
    "# # Get the AUC in the test partition\n",
    "# AUC_adaboost_test_partition = roc_auc_score(y2, adaboost_predicted_probabilities_test_partition)\n",
    "# print('The AUC for the adaboost model in the test partition is', AUC_adaboost_test_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Confusion Matrix (test partition)\n",
    "\n",
    "#### Note: since we are dealing with flagging depression, we are most concerned with capturing all True Positives and avoiding False Negatives, since we want to help people to are depressed (capture True Positives) and avoid accidentally ignoring people who are depressed (avoid False Negatives). Thus, we want to measure positive precision and positive recall together as the F-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The positive precision for the adaboost model in the test partition is 1.0\n",
      "The positive recall for the adaboost model in the test partition is 0.7650978758850479\n",
      "The F-score for the adaboost model in the test partition is 0.8669183577159036\n",
      "The model's accuracy against the test partition is 0.7650978758850479\n",
      "The F-score for the adaboost model in the test partition is 0.8669183577159036\n"
     ]
    }
   ],
   "source": [
    "#convert predicted probabilties into 1s and 0s\n",
    "y_predicted_adaboost = []\n",
    "for i in adaboost_predicted_probabilities_test_partition:\n",
    "    if i >= .5:\n",
    "        y_predicted_adaboost.append(1)\n",
    "    else:\n",
    "        y_predicted_adaboost.append(0)\n",
    "        \n",
    "# create confusion matrix: confusion_matrix(y_true, y_pred)\n",
    "# Note from sci-k itlearn.org:\n",
    "# Thus in binary classification, the count of true negatives is M[0,0], false negatives is M[1,0], \n",
    "    #true positives is M[1,1], and false positives is M[0,1].\n",
    "adaboost_confusion_matrix = confusion_matrix(y2,y_predicted_adaboost)\n",
    "\n",
    "adaboost_true_positive = adaboost_confusion_matrix[1,1]\n",
    "adaboost_true_negative = adaboost_confusion_matrix[0,0]\n",
    "adaboost_false_positive = adaboost_confusion_matrix[0,1]\n",
    "adaboost_false_negative = adaboost_confusion_matrix[1,0]\n",
    "\n",
    "#Calculate positive precision\n",
    "adaboost_positive_precision = adaboost_true_positive / (adaboost_true_positive + adaboost_false_positive)\n",
    "print('The positive precision for the adaboost model in the test partition is',adaboost_positive_precision)\n",
    "\n",
    "#Calculate positive recall\n",
    "adaboost_positive_recall = adaboost_true_positive / (adaboost_true_positive + adaboost_false_negative)\n",
    "print('The positive recall for the adaboost model in the test partition is',adaboost_positive_recall)\n",
    "\n",
    "#Calculate F score\n",
    "adaboost_F_score = (2 * adaboost_positive_precision * adaboost_positive_recall) / (adaboost_positive_precision + adaboost_positive_recall)\n",
    "print('The F-score for the adaboost model in the test partition is',adaboost_F_score)\n",
    "\n",
    "#Calculate accuracy rate\n",
    "print(\"The model's accuracy against the test partition is\",adaboost_classifier_optimal_test_partition.score(x2,y2))\n",
    "\n",
    "#Calculate F score\n",
    "adaboost_F_score = (2 * adaboost_positive_precision * adaboost_positive_recall) / (adaboost_positive_precision + adaboost_positive_recall)\n",
    "print('The F-score for the adaboost model in the test partition is',adaboost_F_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataframe of overall results for easy viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Names</th>\n",
       "      <th>Positive Precision</th>\n",
       "      <th>Positive Recall</th>\n",
       "      <th>F-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k-NN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.706789</td>\n",
       "      <td>0.828209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Classification Tree</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.778426</td>\n",
       "      <td>0.875410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.731778</td>\n",
       "      <td>0.845118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.765098</td>\n",
       "      <td>0.866918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model Names  Positive Precision  Positive Recall   F-Score\n",
       "0                 k-NN                 1.0         0.706789  0.828209\n",
       "1  Classification Tree                 1.0         0.778426  0.875410\n",
       "2        Random Forest                 1.0         0.731778  0.845118\n",
       "3             AdaBoost                 1.0         0.765098  0.866918"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names = ['k-NN', 'Classification Tree', 'Random Forest', 'AdaBoost']\n",
    "\n",
    "# AUC_in_validation_partition = [AUC_k_NN_validation_partition,\n",
    "#                               AUC_classification_tree_validation_partition,\n",
    "#                               AUC_random_forest_validation_partition,\n",
    "#                               AUC_adaboost_validation_partition]\n",
    "\n",
    "\n",
    "# AUC_in_test_partition = [AUC_k_NN_test_partition,\n",
    "#                               AUC_classification_tree_test_partition,\n",
    "#                               AUC_random_forest_test_partition,\n",
    "#                               AUC_adaboost_test_partition]\n",
    "\n",
    "\n",
    "positive_precision = [k_NN_positive_precision,\n",
    "                      classification_tree_positive_precision,\n",
    "                      random_forest_positive_precision,\n",
    "                      adaboost_positive_precision]\n",
    "                    \n",
    "\n",
    "positive_recall = [k_NN_positive_recall,\n",
    "                      classification_tree_positive_recall,\n",
    "                      random_forest_positive_recall,\n",
    "                      adaboost_positive_recall]\n",
    "                      \n",
    "\n",
    "F_score = [k_NN_F_score,\n",
    "                      classification_tree_F_score,\n",
    "                      random_forest_F_score,\n",
    "                      adaboost_F_score]\n",
    "                      \n",
    "summary_data = ({'Model Names': model_names, \n",
    "                'Positive Precision': positive_precision,\n",
    "                'Positive Recall': positive_recall,\n",
    "                'F-Score': F_score})\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "summary_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move AdaBoost accuracy against \"new data\" down here for easy finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Adaboost model accuracy on the new data in the test partition is 0.7650978758850479\n"
     ]
    }
   ],
   "source": [
    "#AdaBoost accuracy\n",
    "adaboost_accuracy = (adaboost_true_positive + adaboost_true_negative) / (adaboost_true_positive + adaboost_true_negative + adaboost_false_positive + adaboost_false_negative)\n",
    "print('The Adaboost model accuracy on the new data in the test partition is', adaboost_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
