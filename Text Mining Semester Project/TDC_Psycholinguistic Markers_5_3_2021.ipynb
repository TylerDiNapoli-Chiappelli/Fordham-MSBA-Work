{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data and Perform Overall Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_data = pd.read_csv(r'C:\\Users\\Home\\Documents\\Text Analytics\\Group Project\\Raw Data\\Training-Validation.csv')\n",
    "trimmed_data = reddit_data.copy()\n",
    "\n",
    "trimmed_data.drop(['score', 'url', 'num_comments', 'created'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and clean each post and title and stick the results in lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords = stopwords.words('english')\n",
    "\n",
    "#Tokenize \"body\".\n",
    "tokenized_posts_list = []\n",
    "# Note: word_tokenize() only accepts 1 string at a time. I must loop through the strings and then tokenize it.\n",
    "for i in trimmed_data['body']:\n",
    "    tokens_list = []\n",
    "    tokens = nltk.word_tokenize(str(i))\n",
    "    for j in tokens:\n",
    "        if j.isalpha():\n",
    "            tokens_list.append(j.lower())\n",
    "    tokenized_posts_list.append(tokens_list)\n",
    "    \n",
    "#Tokenize \"title\". \n",
    "tokenized_titles_list = []\n",
    "# Note: word_tokenize() only accepts 1 string at a time. I must loop through the strings and then tokenize it.\n",
    "for i in trimmed_data['title']:\n",
    "    tokens_list = []\n",
    "    tokens = nltk.word_tokenize(str(i))\n",
    "    for j in tokens:\n",
    "        if j.isalpha():\n",
    "            tokens_list.append(j.lower())\n",
    "    tokenized_titles_list.append(tokens_list)\n",
    "\n",
    "#Add list of fully tokenized and cleaned posts onto existing dataframe. This will allow us to analyze each post and count\n",
    "#stuff in order to create our features\n",
    "trimmed_data['Cleaned and Tokenized Titles'] = tokenized_titles_list\n",
    "trimmed_data['Cleaned and Tokenized Posts'] = tokenized_posts_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the \"Gold Standard\" by classifying each subreddit as 1 (likely depression) or 0 (not likely depression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits_indicative_of_depression = ['depression','depression_help','mentalhealth']\n",
    "\n",
    "manual_classification = []\n",
    "for i in trimmed_data['subreddit']:\n",
    "    \n",
    "    if i in subreddits_indicative_of_depression: \n",
    "        manual_classification.append(1)\n",
    "    else:\n",
    "        manual_classification.append(0)\n",
    "        \n",
    "trimmed_data['Manual Classification'] = manual_classification\n",
    "\n",
    "trimmed_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of the \"Features Grocery Store\" - So we can just go \"shopping\" whenever we need to (meaning create new dataframes with desired features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Psycholinguistic Markers (note: the researchers did not remove stopwords; neither will I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aisle 1: Counts of punctuations and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of Punctuation Characters\n",
    "punctuation = ['~','-',':',';','\"',',','.','?','!']\n",
    "number_of_punctuation_characters = []\n",
    "\n",
    "for i in trimmed_data['body']:\n",
    "    number = 0\n",
    "    for j in punctuation:\n",
    "        number += str(i).count(j)\n",
    "    number_of_punctuation_characters.append(number)\n",
    "\n",
    "#Number of words\n",
    "number_of_words = []\n",
    "\n",
    "for i in trimmed_data['Cleaned and Tokenized Posts']:\n",
    "    number_of_words.append(len(i))\n",
    "    \n",
    "#Number of unique words\n",
    "number_of_unique_words = []\n",
    "\n",
    "for i in trimmed_data['Cleaned and Tokenized Posts']:\n",
    "    number_of_unique_words.append(len(set(i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aisle 2: Parts of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The remaining needed Psycholinguistic Markers are all parts of speech. The first step is to tag the P.O.S once for the whole document\n",
    "#run the P.O.S. tagger on the entire tokenized \"tokenized_posts_list\" list (remember: this is a list of lists)\n",
    "POS_list = []\n",
    "for i in trimmed_data['Cleaned and Tokenized Posts']:\n",
    "    part_of_speech_tags = nltk.pos_tag(i)\n",
    "    POS_list.append(part_of_speech_tags)\n",
    "\n",
    "#Number of Verbs\n",
    "number_of_all_verbs = []\n",
    "for i in POS_list:\n",
    "    all_verbs = [(word,tag) for (word,tag) in i if tag.startswith('V')]\n",
    "    number_of_all_verbs.append(len(all_verbs))\n",
    "    \n",
    "#Number of Adjectives\n",
    "number_of_adjectives = []\n",
    "for i in POS_list:\n",
    "    adjectives = [(word,tag) for (word,tag) in i if tag.startswith('J')]\n",
    "    number_of_adjectives.append(len(adjectives))\n",
    "    \n",
    "#Number of Conjunctions (coordinating conjunctions only)\n",
    "number_of_conjunctions = []\n",
    "for i in POS_list:\n",
    "    conjunctions = [(word,tag) for (word,tag) in i if tag.startswith('CC')]\n",
    "    number_of_conjunctions.append(len(conjunctions))\n",
    "\n",
    "#Number of Prepositions (includes prepositions and subordinating conjunctions)\n",
    "number_of_prepositions = []\n",
    "for i in POS_list:\n",
    "    prepositions = [(word,tag) for (word,tag) in i if tag.startswith('IN')]\n",
    "    number_of_prepositions.append(len(prepositions))\n",
    "    \n",
    "#Number of Infinitives\n",
    "number_of_infinitives = []\n",
    "for i in POS_list:\n",
    "    infinitives = [(word,tag) for (word,tag) in i if tag.endswith('VB')]\n",
    "    number_of_infinitives.append(len(infinitives))\n",
    "    \n",
    "#Number of Past Tense Verbs\n",
    "number_of_past_tense_verbs = []\n",
    "for i in POS_list:\n",
    "    past_tense_verbs = [(word,tag) for (word,tag) in i if tag.startswith('VBD')]\n",
    "    number_of_past_tense_verbs.append(len(past_tense_verbs))\n",
    "    \n",
    "#Number of First Person Verbs (this will be a little inexact; this is the rough combo of VBD and VBP)\n",
    "number_of_first_person_verbs = []\n",
    "for i in POS_list:\n",
    "    first_person_verbs = [(word,tag) for (word,tag) in i if tag.startswith('VBD') or tag.startswith('VBP')]\n",
    "    number_of_first_person_verbs.append(len(first_person_verbs))\n",
    "    \n",
    "#Number of Third-Person Verbs (this will undercount. VBZ is 3rd person singular only; combining with anything else will overcount alot)\n",
    "number_of_third_person_verbs = []\n",
    "for i in POS_list:\n",
    "    third_person_verbs = [(word,tag) for (word,tag) in i if tag.startswith('VBZ')]\n",
    "    number_of_third_person_verbs.append(len(third_person_verbs))\n",
    "    \n",
    "#Number of Pronouns\n",
    "number_of_pronouns = []\n",
    "NLTK_pronouns = ['PRP', 'PRP$', 'WP', 'WP$']\n",
    "for i in POS_list:\n",
    "    pronouns = [(word,tag) for (word,tag) in i if tag in NLTK_pronouns]\n",
    "    number_of_pronouns.append(len(pronouns))\n",
    "    \n",
    "#Number of First-Person Pronouns\n",
    "number_of_first_person_pronouns = []\n",
    "list_of_first_person_pronouns = ['We', 'us', 'our','ourselves', 'I', 'me', 'my', 'mine', 'myself']\n",
    "for i in POS_list:\n",
    "    first_person_pronouns = [(word,tag) for (word,tag) in i if word in list_of_first_person_pronouns]\n",
    "    number_of_first_person_pronouns.append(len(first_person_pronouns))\n",
    "    \n",
    "#Number of Singular First-Person Pronouns\n",
    "number_of_singular_first_person_pronouns = []\n",
    "list_of_singular_first_person_pronouns = ['I', 'me', 'my', 'mine', 'myself']\n",
    "for i in POS_list:\n",
    "    singular_first_person_pronouns = [(word,tag) for (word,tag) in i if word in list_of_singular_first_person_pronouns]\n",
    "    number_of_singular_first_person_pronouns.append(len(singular_first_person_pronouns))\n",
    "    \n",
    "#Number of Plural First-Person Pronouns\n",
    "number_of_plural_first_person_pronouns = []\n",
    "list_of_plural_first_person_pronouns = ['We', 'us', 'our','ourselves']\n",
    "for i in POS_list:\n",
    "    plural_first_person_pronouns = [(word,tag) for (word,tag) in i if word in list_of_plural_first_person_pronouns]\n",
    "    number_of_plural_first_person_pronouns.append(len(plural_first_person_pronouns))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aisle 3: Entire Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because of the non-standard use of punctuation to end sentences, this count is not perfect. But, eyeballing the first 5 entries\n",
    "#it looks good enough\n",
    "number_of_sentences = []\n",
    "for i in trimmed_data['body']:\n",
    "    sentences = nltk.sent_tokenize(str(i))\n",
    "    number_of_sentences.append(len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Paper 1\" Dataframe - The Psycholinguistic Markers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Creation of all needed new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(N punctuation characters) / (N words)\n",
    "punctuation_divided_by_words = [i / j if j > 0 else 'divide by zero' for i, j in zip(number_of_punctuation_characters, number_of_words)]\n",
    "\n",
    "#(N unique words) / (N words)\n",
    "unique_words_divided_by_words = [i / j if j > 0 else 'divide by zero' for i, j in zip(number_of_unique_words, number_of_words)]\n",
    "\n",
    "#(N verbs) / (N adjectives)\n",
    "verbs_divided_by_adjectives = [i / j if j > 0 else 'divide by zero' for i, j in zip(number_of_all_verbs, number_of_adjectives)]\n",
    "\n",
    "#(N conjunctions + N prepositions) / (N sentences)\n",
    "conjunctions_plus_prepositions_divided_by_sentences = [(i + k) / j if j > 0 else 'divide by zero' for i,k,j in zip(number_of_conjunctions, number_of_prepositions, number_of_sentences)]\n",
    "\n",
    "#(N infinitives) / (N verbs)\n",
    "infintives_divided_by_verbs = [i / j if j > 0 else 'divide by zero' for i, j in zip(number_of_infinitives, number_of_all_verbs)]\n",
    "\n",
    "#(N singular first person past tense verbs) / (N verbs) (note: inexactly calculated)\n",
    "SFPPT_verbs_divided_by_verbs = [i / j if j > 0 else 'divide by zero' for i, j in zip(number_of_past_tense_verbs, number_of_all_verbs)]\n",
    "\n",
    "#(N first person verbs) / (N verbs) (inexactly calculated)\n",
    "first_person_verbs_divided_by_verbs = [i / j if j > 0 else 'divide by zero' for i, j in zip(number_of_first_person_verbs, number_of_all_verbs)]\n",
    "\n",
    "#(N third person verbs) / (N verbs) (inexactly calculated)\n",
    "third_person_verbs_divided_by_verbs = [i / j if j > 0 else 'divide by zero' for i, j in zip(number_of_third_person_verbs, number_of_all_verbs)]\n",
    "\n",
    "#(N first person pronouns) / (N pronouns)\n",
    "first_person_pronouns_divided_by_pronouns = [i / j if j > 0 else 'divide by zero' for i, j in zip(number_of_first_person_pronouns, number_of_pronouns)]\n",
    "\n",
    "#(N singular first person pronouns) / (N pronouns)\n",
    "singular_first_person_pronouns_divided_by_pronouns = [i / j if j > 0 else 'divide by zero' for i, j in zip(number_of_singular_first_person_pronouns, number_of_pronouns)]\n",
    "\n",
    "#(N plural first person pronouns) / (N pronouns)\n",
    "plural_first_person_pronouns_divided_by_pronouns = [i / j if j > 0 else 'divide by zero' for i, j in zip(number_of_plural_first_person_pronouns, number_of_pronouns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Creation of \"Dataframe With Psycholinguistic Markers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PM_data = ({'Manual Classification': trimmed_data['Manual Classification'], \n",
    "            'Subreddit': trimmed_data['subreddit'],\n",
    "            'Post Title': trimmed_data['title'], \n",
    "            'Post Body': trimmed_data['body'], \n",
    "            '(N punctuation characters) / (N words)': punctuation_divided_by_words,\n",
    "            '(N unique words) / (N words)': unique_words_divided_by_words,\n",
    "            '(N verbs) / (N adjectives)': verbs_divided_by_adjectives,\n",
    "            '(N conjunctions + N prepositions) / (N sentences)': conjunctions_plus_prepositions_divided_by_sentences,\n",
    "            '(N infinitives) / (N verbs)': infintives_divided_by_verbs,\n",
    "            '(N singular first person past tense verbs) / (N verbs)': SFPPT_verbs_divided_by_verbs,\n",
    "            '(N first person verbs) / (N verbs)': first_person_verbs_divided_by_verbs,\n",
    "            '(N third person verbs) / (N verbs)': third_person_verbs_divided_by_verbs,\n",
    "            '(N first person pronouns) / (N pronouns)': first_person_pronouns_divided_by_pronouns,\n",
    "            '(N singular first person pronouns) / (N pronouns)': singular_first_person_pronouns_divided_by_pronouns,\n",
    "            '(N plural first person pronouns) / (N pronouns)': plural_first_person_pronouns_divided_by_pronouns})\n",
    "\n",
    "PM_dataframe = pd.DataFrame(data = PM_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manual Classification</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Post Title</th>\n",
       "      <th>Post Body</th>\n",
       "      <th>(N punctuation characters) / (N words)</th>\n",
       "      <th>(N unique words) / (N words)</th>\n",
       "      <th>(N verbs) / (N adjectives)</th>\n",
       "      <th>(N conjunctions + N prepositions) / (N sentences)</th>\n",
       "      <th>(N infinitives) / (N verbs)</th>\n",
       "      <th>(N singular first person past tense verbs) / (N verbs)</th>\n",
       "      <th>(N first person verbs) / (N verbs)</th>\n",
       "      <th>(N third person verbs) / (N verbs)</th>\n",
       "      <th>(N first person pronouns) / (N pronouns)</th>\n",
       "      <th>(N singular first person pronouns) / (N pronouns)</th>\n",
       "      <th>(N plural first person pronouns) / (N pronouns)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>depression</td>\n",
       "      <td>Our most-broken and least-understood rules is ...</td>\n",
       "      <td>We understand that most people who reply immed...</td>\n",
       "      <td>0.133423</td>\n",
       "      <td>0.447439</td>\n",
       "      <td>1.88406</td>\n",
       "      <td>3.594595</td>\n",
       "      <td>0.376923</td>\n",
       "      <td>0.0769231</td>\n",
       "      <td>0.292308</td>\n",
       "      <td>0.169231</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>depression</td>\n",
       "      <td>Regular Check-In Post, with important reminder...</td>\n",
       "      <td>Welcome to /r/depression's check-in post - a p...</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>1.91304</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.0681818</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.159091</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>depression</td>\n",
       "      <td>I Feel Like I Live In A World Where Evil Wins</td>\n",
       "      <td>Hello  everyone, little short intro here. I am...</td>\n",
       "      <td>0.135802</td>\n",
       "      <td>0.510288</td>\n",
       "      <td>2.86364</td>\n",
       "      <td>3.071429</td>\n",
       "      <td>0.206349</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.0952381</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>depression</td>\n",
       "      <td>I just need to tell someone this</td>\n",
       "      <td>\\nI’m 17. Today is my Dads 70th birthday.  Tha...</td>\n",
       "      <td>0.0766129</td>\n",
       "      <td>0.504032</td>\n",
       "      <td>2.29167</td>\n",
       "      <td>2.235294</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.309091</td>\n",
       "      <td>0.327273</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>depression</td>\n",
       "      <td>Im pretty sure i stay up so late because I don...</td>\n",
       "      <td>I dont know if that makes sense, but thats how...</td>\n",
       "      <td>0.0833333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>divide by zero</td>\n",
       "      <td>divide by zero</td>\n",
       "      <td>divide by zero</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Manual Classification   Subreddit  \\\n",
       "0                      1  depression   \n",
       "1                      1  depression   \n",
       "2                      1  depression   \n",
       "3                      1  depression   \n",
       "4                      1  depression   \n",
       "\n",
       "                                          Post Title  \\\n",
       "0  Our most-broken and least-understood rules is ...   \n",
       "1  Regular Check-In Post, with important reminder...   \n",
       "2      I Feel Like I Live In A World Where Evil Wins   \n",
       "3                   I just need to tell someone this   \n",
       "4  Im pretty sure i stay up so late because I don...   \n",
       "\n",
       "                                           Post Body  \\\n",
       "0  We understand that most people who reply immed...   \n",
       "1  Welcome to /r/depression's check-in post - a p...   \n",
       "2  Hello  everyone, little short intro here. I am...   \n",
       "3  \\nI’m 17. Today is my Dads 70th birthday.  Tha...   \n",
       "4  I dont know if that makes sense, but thats how...   \n",
       "\n",
       "  (N punctuation characters) / (N words) (N unique words) / (N words)  \\\n",
       "0                               0.133423                     0.447439   \n",
       "1                               0.150943                     0.566038   \n",
       "2                               0.135802                     0.510288   \n",
       "3                              0.0766129                     0.504032   \n",
       "4                              0.0833333                     0.916667   \n",
       "\n",
       "  (N verbs) / (N adjectives)  \\\n",
       "0                    1.88406   \n",
       "1                    1.91304   \n",
       "2                    2.86364   \n",
       "3                    2.29167   \n",
       "4                          2   \n",
       "\n",
       "   (N conjunctions + N prepositions) / (N sentences)  \\\n",
       "0                                           3.594595   \n",
       "1                                           3.600000   \n",
       "2                                           3.071429   \n",
       "3                                           2.235294   \n",
       "4                                           2.000000   \n",
       "\n",
       "  (N infinitives) / (N verbs)  \\\n",
       "0                    0.376923   \n",
       "1                    0.340909   \n",
       "2                    0.206349   \n",
       "3                         0.2   \n",
       "4                           0   \n",
       "\n",
       "  (N singular first person past tense verbs) / (N verbs)  \\\n",
       "0                                          0.0769231       \n",
       "1                                          0.0681818       \n",
       "2                                           0.222222       \n",
       "3                                           0.127273       \n",
       "4                                                  0       \n",
       "\n",
       "  (N first person verbs) / (N verbs) (N third person verbs) / (N verbs)  \\\n",
       "0                           0.292308                           0.169231   \n",
       "1                               0.25                           0.159091   \n",
       "2                           0.380952                          0.0952381   \n",
       "3                           0.309091                           0.327273   \n",
       "4                                0.5                                0.5   \n",
       "\n",
       "  (N first person pronouns) / (N pronouns)  \\\n",
       "0                                    0.125   \n",
       "1                                     0.12   \n",
       "2                                 0.444444   \n",
       "3                                 0.393939   \n",
       "4                           divide by zero   \n",
       "\n",
       "  (N singular first person pronouns) / (N pronouns)  \\\n",
       "0                                          0.046875   \n",
       "1                                                 0   \n",
       "2                                          0.111111   \n",
       "3                                          0.393939   \n",
       "4                                    divide by zero   \n",
       "\n",
       "  (N plural first person pronouns) / (N pronouns)  \n",
       "0                                        0.078125  \n",
       "1                                            0.12  \n",
       "2                                        0.333333  \n",
       "3                                               0  \n",
       "4                                  divide by zero  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PM_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Models (with Psycholinguistic Markers as features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab the Psycholingustic Markers dataframe and get rid of any row with \"divide by zero\".\n",
    "## Please note that I researched the given warning message and the Python community agrees that it is a bug caused by Numpy and Pandas fighting with each other. It is safe to ignore this warning when conducting this particular operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Home\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manual Classification</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Post Title</th>\n",
       "      <th>Post Body</th>\n",
       "      <th>(N punctuation characters) / (N words)</th>\n",
       "      <th>(N unique words) / (N words)</th>\n",
       "      <th>(N verbs) / (N adjectives)</th>\n",
       "      <th>(N conjunctions + N prepositions) / (N sentences)</th>\n",
       "      <th>(N infinitives) / (N verbs)</th>\n",
       "      <th>(N singular first person past tense verbs) / (N verbs)</th>\n",
       "      <th>(N first person verbs) / (N verbs)</th>\n",
       "      <th>(N third person verbs) / (N verbs)</th>\n",
       "      <th>(N first person pronouns) / (N pronouns)</th>\n",
       "      <th>(N singular first person pronouns) / (N pronouns)</th>\n",
       "      <th>(N plural first person pronouns) / (N pronouns)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>depression</td>\n",
       "      <td>Our most-broken and least-understood rules is ...</td>\n",
       "      <td>We understand that most people who reply immed...</td>\n",
       "      <td>0.133423</td>\n",
       "      <td>0.447439</td>\n",
       "      <td>1.88406</td>\n",
       "      <td>3.594595</td>\n",
       "      <td>0.376923</td>\n",
       "      <td>0.0769231</td>\n",
       "      <td>0.292308</td>\n",
       "      <td>0.169231</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>depression</td>\n",
       "      <td>Regular Check-In Post, with important reminder...</td>\n",
       "      <td>Welcome to /r/depression's check-in post - a p...</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>1.91304</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.0681818</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.159091</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>depression</td>\n",
       "      <td>I Feel Like I Live In A World Where Evil Wins</td>\n",
       "      <td>Hello  everyone, little short intro here. I am...</td>\n",
       "      <td>0.135802</td>\n",
       "      <td>0.510288</td>\n",
       "      <td>2.86364</td>\n",
       "      <td>3.071429</td>\n",
       "      <td>0.206349</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.0952381</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>depression</td>\n",
       "      <td>I just need to tell someone this</td>\n",
       "      <td>\\nI’m 17. Today is my Dads 70th birthday.  Tha...</td>\n",
       "      <td>0.0766129</td>\n",
       "      <td>0.504032</td>\n",
       "      <td>2.29167</td>\n",
       "      <td>2.235294</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.309091</td>\n",
       "      <td>0.327273</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>depression</td>\n",
       "      <td>im 14. do i deserve to be depressed? or am i j...</td>\n",
       "      <td>my day started off with my mom yelling at me b...</td>\n",
       "      <td>0.062954</td>\n",
       "      <td>0.469734</td>\n",
       "      <td>3.28571</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.206522</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.532609</td>\n",
       "      <td>0.0543478</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Manual Classification   Subreddit  \\\n",
       "0                      1  depression   \n",
       "1                      1  depression   \n",
       "2                      1  depression   \n",
       "3                      1  depression   \n",
       "4                      1  depression   \n",
       "\n",
       "                                          Post Title  \\\n",
       "0  Our most-broken and least-understood rules is ...   \n",
       "1  Regular Check-In Post, with important reminder...   \n",
       "2      I Feel Like I Live In A World Where Evil Wins   \n",
       "3                   I just need to tell someone this   \n",
       "4  im 14. do i deserve to be depressed? or am i j...   \n",
       "\n",
       "                                           Post Body  \\\n",
       "0  We understand that most people who reply immed...   \n",
       "1  Welcome to /r/depression's check-in post - a p...   \n",
       "2  Hello  everyone, little short intro here. I am...   \n",
       "3  \\nI’m 17. Today is my Dads 70th birthday.  Tha...   \n",
       "4  my day started off with my mom yelling at me b...   \n",
       "\n",
       "  (N punctuation characters) / (N words) (N unique words) / (N words)  \\\n",
       "0                               0.133423                     0.447439   \n",
       "1                               0.150943                     0.566038   \n",
       "2                               0.135802                     0.510288   \n",
       "3                              0.0766129                     0.504032   \n",
       "4                               0.062954                     0.469734   \n",
       "\n",
       "  (N verbs) / (N adjectives)  \\\n",
       "0                    1.88406   \n",
       "1                    1.91304   \n",
       "2                    2.86364   \n",
       "3                    2.29167   \n",
       "4                    3.28571   \n",
       "\n",
       "   (N conjunctions + N prepositions) / (N sentences)  \\\n",
       "0                                           3.594595   \n",
       "1                                           3.600000   \n",
       "2                                           3.071429   \n",
       "3                                           2.235294   \n",
       "4                                           9.000000   \n",
       "\n",
       "  (N infinitives) / (N verbs)  \\\n",
       "0                    0.376923   \n",
       "1                    0.340909   \n",
       "2                    0.206349   \n",
       "3                         0.2   \n",
       "4                    0.206522   \n",
       "\n",
       "  (N singular first person past tense verbs) / (N verbs)  \\\n",
       "0                                          0.0769231       \n",
       "1                                          0.0681818       \n",
       "2                                           0.222222       \n",
       "3                                           0.127273       \n",
       "4                                           0.326087       \n",
       "\n",
       "  (N first person verbs) / (N verbs) (N third person verbs) / (N verbs)  \\\n",
       "0                           0.292308                           0.169231   \n",
       "1                               0.25                           0.159091   \n",
       "2                           0.380952                          0.0952381   \n",
       "3                           0.309091                           0.327273   \n",
       "4                           0.532609                          0.0543478   \n",
       "\n",
       "  (N first person pronouns) / (N pronouns)  \\\n",
       "0                                    0.125   \n",
       "1                                     0.12   \n",
       "2                                 0.444444   \n",
       "3                                 0.393939   \n",
       "4                                 0.703704   \n",
       "\n",
       "  (N singular first person pronouns) / (N pronouns)  \\\n",
       "0                                          0.046875   \n",
       "1                                                 0   \n",
       "2                                          0.111111   \n",
       "3                                          0.393939   \n",
       "4                                          0.703704   \n",
       "\n",
       "  (N plural first person pronouns) / (N pronouns)  \n",
       "0                                        0.078125  \n",
       "1                                            0.12  \n",
       "2                                        0.333333  \n",
       "3                                               0  \n",
       "4                                               0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Copy existing dataframe\n",
    "PM_dataframe_for_ML_models = PM_dataframe.copy()\n",
    "\n",
    "#Drop any row which contains the text string \"divide by zero\"\n",
    "all_columns = list(PM_dataframe_for_ML_models.columns)\n",
    "\n",
    "for i in all_columns:\n",
    "    divide_by_zero_filter = PM_dataframe_for_ML_models[i] == 'divide by zero'\n",
    "    PM_dataframe_for_ML_models.drop(PM_dataframe_for_ML_models[divide_by_zero_filter].index, inplace = True)\n",
    "\n",
    "PM_dataframe_for_ML_models.reset_index(drop = True, inplace = True)\n",
    "PM_dataframe_for_ML_models.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup: Generate Variable List, Standardize Values, and Partition Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting Up Numerical Variables (there are no categorical variables). Since I create the dataframe in the above code, I can\n",
    "#safely drop 'manual classification', 'subreddit', 'post title', and 'post body' by directly slicing the list by index\n",
    "nvar_list = list(PM_dataframe_for_ML_models.columns)\n",
    "del nvar_list[0:4]\n",
    "\n",
    "#Drop unneeded text columns from dataframe which will be used in Machine Learning models\n",
    "PM_dataframe_for_ML_models.drop(['Subreddit', 'Post Title', 'Post Body'], axis = 1, inplace=True)\n",
    "\n",
    "#Standardizing Numerical variables\n",
    "standardized_PM_dataframe_for_ML_models = PM_dataframe_for_ML_models.copy()\n",
    "\n",
    "original_column_values = PM_dataframe_for_ML_models[nvar_list]\n",
    "sample_mean = PM_dataframe_for_ML_models[nvar_list].mean()\n",
    "sample_stddev = PM_dataframe_for_ML_models[nvar_list].std()\n",
    "\n",
    "standardized_PM_dataframe_for_ML_models[nvar_list] = ((original_column_values - sample_mean)/sample_stddev)\n",
    "\n",
    "\n",
    "\n",
    "#Data Partition\n",
    "#Splitting the data into our partitions will return two dataframes, so we must prep like so:\n",
    "test_partition_size = .2\n",
    "data_to_be_partitioned = standardized_PM_dataframe_for_ML_models\n",
    "\n",
    "non_test_data, test_data = train_test_split(data_to_be_partitioned, test_size = test_partition_size, random_state = 1)\n",
    "\n",
    "#non_test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model in the Training/Validation Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                           0\n",
      "(N punctuation characters) / (N words)              0.360646\n",
      "(N unique words) / (N words)                        0.891401\n",
      "(N verbs) / (N adjectives)                         -0.282906\n",
      "(N conjunctions + N prepositions) / (N sentences)   0.105490\n",
      "(N infinitives) / (N verbs)                        -0.059542\n",
      "(N singular first person past tense verbs) / (N... -0.754415\n",
      "(N first person verbs) / (N verbs)                 -0.140026\n",
      "(N third person verbs) / (N verbs)                 -0.464957\n",
      "(N first person pronouns) / (N pronouns)            0.000000\n",
      "(N singular first person pronouns) / (N pronouns)   1.033547\n",
      "(N plural first person pronouns) / (N pronouns)    -0.197621\n",
      "Intercept                                           0.957425\n",
      "\n",
      "This model's optimal alpha in the validation partition is [3.99961596]\n",
      "The AUC of the optimal model in the validation partition is 0.8724610111449711\n"
     ]
    }
   ],
   "source": [
    "#Establish, for Python's sake, the independent and dependent variables\n",
    "DV = 'Manual Classification'\n",
    "y = non_test_data[DV]\n",
    "x = non_test_data.drop(columns = [DV])\n",
    "\n",
    "#Create Lin Hao's function to return the logistic regression coefficient results in a nice format\n",
    "def summary_coef(model_object):\n",
    "    n_predictors = x.shape[1]\n",
    "    model_coef = pd.DataFrame(model_object.coef_.reshape(1,n_predictors),columns = x.columns.values)\n",
    "    model_coef['Intercept'] = model_object.intercept_\n",
    "    return (model_coef.transpose())\n",
    "\n",
    "#Setup Logistic Regression with k-folds = 5\n",
    "kfolds = 5\n",
    "\n",
    "#Establish alpha range for Python to search within\n",
    "min_alpha = .01\n",
    "max_alpha = 100\n",
    "\n",
    "max_C = 1/min_alpha\n",
    "min_C = 1/max_alpha\n",
    "\n",
    "#Because there are infinite values between min_alpha and max_alpha, we must specify how many alphas Python should look for\n",
    "#Python will then divide that interval into an even number of searches. We need numpy for this\n",
    "n_candidates = 5000\n",
    "c_list= list(np.linspace(min_C, max_C, num = n_candidates))\n",
    "\n",
    "#Run logistic regression, use \"scoring = roc_auc\" to get the Area Under the Curve, and send it into the \"nice formatting\" function\n",
    "classifier_optimal = LogisticRegressionCV(Cs = c_list, cv=kfolds, scoring = 'roc_auc', penalty = 'l1',solver='saga',max_iter=200, random_state=1, n_jobs = -1).fit(x,y)\n",
    "print(summary_coef(classifier_optimal))\n",
    "\n",
    "#Find the optimal selected alpha\n",
    "print(\"\\nThis model's optimal alpha in the validation partition is\",1/classifier_optimal.C_)\n",
    "\n",
    "# predict probabilities\n",
    "logistic_regression_predicted_probabilities_validation_partition = classifier_optimal.predict_proba(x)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "logistic_regression_predicted_probabilities_validation_partition = logistic_regression_predicted_probabilities_validation_partition[:, 1]\n",
    "\n",
    "# calculate AUC\n",
    "AUC_logistic_regression_validation_partition = roc_auc_score(y, logistic_regression_predicted_probabilities_validation_partition)\n",
    "print('The AUC of the optimal model in the validation partition is', AUC_logistic_regression_validation_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model in the Test Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                           0\n",
      "(N punctuation characters) / (N words)              0.415034\n",
      "(N unique words) / (N words)                        0.830570\n",
      "(N verbs) / (N adjectives)                         -0.079822\n",
      "(N conjunctions + N prepositions) / (N sentences)   0.273052\n",
      "(N infinitives) / (N verbs)                        -0.015371\n",
      "(N singular first person past tense verbs) / (N... -0.778614\n",
      "(N first person verbs) / (N verbs)                 -0.122146\n",
      "(N third person verbs) / (N verbs)                 -0.501808\n",
      "(N first person pronouns) / (N pronouns)            0.000000\n",
      "(N singular first person pronouns) / (N pronouns)   1.310021\n",
      "(N plural first person pronouns) / (N pronouns)    -0.298459\n",
      "Intercept                                           1.180626\n",
      "\n",
      "This model's optimal alpha in the test partition is [1.36972789]\n",
      "The AUC of the optimal model in the test partition is 0.8792966183086489\n"
     ]
    }
   ],
   "source": [
    "#Establish, for Python's sake, the independent and dependent variables\n",
    "DV = 'Manual Classification'\n",
    "y2 = test_data[DV]\n",
    "x2 = test_data.drop(columns = [DV])\n",
    "\n",
    "#Run logistic regression, use \"scoring = roc_auc\" to get the Area Under the Curve, and send it into the \"nice formatting\" function\n",
    "classifier_optimal_2 = LogisticRegressionCV(Cs = c_list, cv=kfolds, scoring = 'roc_auc', penalty = 'l1',solver='saga',max_iter=200, random_state=1, n_jobs = -1).fit(x2,y2)\n",
    "print(summary_coef(classifier_optimal_2))\n",
    "\n",
    "#Find the optimal selected alpha\n",
    "print(\"\\nThis model's optimal alpha in the test partition is\",1/classifier_optimal_2.C_)\n",
    "\n",
    "# predict probabilities\n",
    "logistic_regression_predicted_probabilities_test_partition = classifier_optimal_2.predict_proba(x2)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "logistic_regression_predicted_probabilities_test_partition = logistic_regression_predicted_probabilities_test_partition[:, 1]\n",
    "\n",
    "# calculate AUC\n",
    "AUC_logistic_regression_test_partition = roc_auc_score(y2, logistic_regression_predicted_probabilities_test_partition)\n",
    "print('The AUC of the optimal model in the test partition is', AUC_logistic_regression_test_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Confusion Matrix (validation partition)\n",
    "\n",
    "#### Note: since we are dealing with flagging depression, we are most concerned with capturing all True Positives and avoiding False Negatives, since we want to help people to are depressed (capture True Positives) and avoid accidentally ignoring people who are depressed (avoid False Negatives). Thus, we want to measure positive precision and positive recall together as the F-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The positive precision for the logistic regression model in the validation partition is 0.8342516069788797\n",
      "The positive recall for the logistic regression model in the validation partition is 0.8648262732032366\n",
      "The F-score for the logistic regression model in the validation partition is 0.8492638466931526\n"
     ]
    }
   ],
   "source": [
    "#convert predicted probabilties into 1s and 0s\n",
    "y_predicted_logistic_regression = []\n",
    "for i in logistic_regression_predicted_probabilities_validation_partition:\n",
    "    if i >= .5:\n",
    "        y_predicted_logistic_regression.append(1)\n",
    "    else:\n",
    "        y_predicted_logistic_regression.append(0)\n",
    "        \n",
    "#create confusion matrix: confusion_matrix(y_true, y_pred)\n",
    "#Note from sci-k itlearn.org:\n",
    "#Thus in binary classification, the count of true negatives is M[0,0], false negatives is M[1,0], \n",
    "    #true positives is M[1,1], and false positives is M[0,1].\n",
    "logistic_regression_confusion_matrix = confusion_matrix(y, y_predicted_logistic_regression)\n",
    "\n",
    "logistic_regression_true_positive = logistic_regression_confusion_matrix[1,1]\n",
    "logistic_regression_true_negative = logistic_regression_confusion_matrix[0,0]\n",
    "logistic_regression_false_positive = logistic_regression_confusion_matrix[0,1]\n",
    "logistic_regression_false_negative = logistic_regression_confusion_matrix[1,0]\n",
    "\n",
    "#Calculate positive precision\n",
    "logistic_regression_positive_precision = logistic_regression_true_positive / (logistic_regression_true_positive + logistic_regression_false_positive)\n",
    "print('The positive precision for the logistic regression model in the validation partition is',logistic_regression_positive_precision)\n",
    "\n",
    "#Calculate positive recall\n",
    "logistic_regression_positive_recall = logistic_regression_true_positive / (logistic_regression_true_positive + logistic_regression_false_negative)\n",
    "print('The positive recall for the logistic regression model in the validation partition is',logistic_regression_positive_recall)\n",
    "\n",
    "#Calculate F score\n",
    "logistic_regression_F_score = (2 * logistic_regression_positive_precision * logistic_regression_positive_recall) / (logistic_regression_positive_precision + logistic_regression_positive_recall)\n",
    "print('The F-score for the logistic regression model in the validation partition is',logistic_regression_F_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model in the Training/Validation Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal k in the validation partition is 63\n",
      "The AUC of the optimal model in the validation partition is 0.8927928182003623\n"
     ]
    }
   ],
   "source": [
    "#Establish, for Python's sake, the independent and dependent variables\n",
    "DV = 'Manual Classification'\n",
    "y = non_test_data[DV]\n",
    "x = non_test_data.drop(columns = [DV])\n",
    "\n",
    "# Run Nearest Neighbors with k-fold cross validation with k=5\n",
    "kfolds = 5\n",
    "\n",
    "# Here we specify within which range of Ks we will search through and save that range into a dictionary\n",
    "max_k = 200\n",
    "parameters_grid = {'n_neighbors': list(range(1, max_k + 1))}\n",
    "\n",
    "#Setup a k-NN model which will search through all of our specified hyperparameters (the ks) and then apply the model to our data\n",
    "k_NN = GridSearchCV(KNeighborsClassifier(metric = 'euclidean'), parameters_grid, scoring='roc_auc', cv=kfolds, n_jobs=-1)\n",
    "k_NN.fit(x,y)\n",
    "classifier_best_KNN = k_NN.best_estimator_\n",
    "\n",
    "# Display optimal k\n",
    "print('The optimal k in the validation partition is',classifier_best_KNN.n_neighbors)\n",
    "\n",
    "# predict probabilities\n",
    "k_NN_predicted_probabilities_validation_partition = classifier_best_KNN.predict_proba(x)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "k_NN_predicted_probabilities_validation_partition = k_NN_predicted_probabilities_validation_partition[:, 1]\n",
    "\n",
    "# calculate AUC\n",
    "AUC_k_NN_validation_partition = roc_auc_score(y, k_NN_predicted_probabilities_validation_partition)\n",
    "print('The AUC of the optimal model in the validation partition is', AUC_k_NN_validation_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model in the Test Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal k in the test partition is 104\n",
      "The AUC of the optimal model in the test partition is 0.8913776980235555\n"
     ]
    }
   ],
   "source": [
    "#Establish, for Python's sake, the independent and dependent variables\n",
    "DV = 'Manual Classification'\n",
    "y2 = test_data[DV]\n",
    "x2 = test_data.drop(columns = [DV])\n",
    "\n",
    "#Setup a k-NN model which will search through all of our specified hyperparameters (the ks) and then apply the model to our data\n",
    "k_NN_2 = GridSearchCV(KNeighborsClassifier(metric = 'euclidean'), parameters_grid, scoring='roc_auc', cv=kfolds, n_jobs=-1)\n",
    "k_NN_2.fit(x2,y2)\n",
    "classifier_best_KNN_2 = k_NN_2.best_estimator_\n",
    "\n",
    "# Display optimal k\n",
    "print('The optimal k in the test partition is',classifier_best_KNN_2.n_neighbors)\n",
    "\n",
    "# predict probabilities\n",
    "k_NN_predicted_probabilities_test_partition = classifier_best_KNN_2.predict_proba(x2)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "k_NN_predicted_probabilities_test_partition = k_NN_predicted_probabilities_test_partition[:, 1]\n",
    "\n",
    "# calculate AUC\n",
    "AUC_k_NN_test_partition = roc_auc_score(y2, k_NN_predicted_probabilities_test_partition)\n",
    "print('The AUC of the optimal model in the test partition is', AUC_k_NN_test_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN Confusion Matrix (validation partition)\n",
    "\n",
    "#### Note: since we are dealing with flagging depression, we are most concerned with capturing all True Positives and avoiding False Negatives, since we want to help people to are depressed (capture True Positives) and avoid accidentally ignoring people who are depressed (avoid False Negatives). Thus, we want to measure positive precision and positive recall together as the F-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The positive precision for the k-NN model in the validation partition is 0.8584409373505499\n",
      "The positive recall for the k-NN model in the validation partition is 0.8543550690147549\n",
      "The F-score for the k-NN model in the validation partition is 0.8563931297709924\n"
     ]
    }
   ],
   "source": [
    "#convert predicted probabilties into 1s and 0s\n",
    "y_predicted_k_NN = []\n",
    "for i in k_NN_predicted_probabilities_validation_partition:\n",
    "    if i >= .5:\n",
    "        y_predicted_k_NN.append(1)\n",
    "    else:\n",
    "        y_predicted_k_NN.append(0)\n",
    "        \n",
    "#create confusion matrix: confusion_matrix(y_true, y_pred)\n",
    "#Note from sci-k itlearn.org:\n",
    "#Thus in binary classification, the count of true negatives is M[0,0], false negatives is M[1,0], \n",
    "    #true positives is M[1,1], and false positives is M[0,1].\n",
    "k_NN_confusion_matrix = confusion_matrix(y,y_predicted_k_NN)\n",
    "\n",
    "k_NN_true_positive = k_NN_confusion_matrix[1,1]\n",
    "k_NN_true_negative = k_NN_confusion_matrix[0,0]\n",
    "k_NN_false_positive = k_NN_confusion_matrix[0,1]\n",
    "k_NN_false_negative = k_NN_confusion_matrix[1,0]\n",
    "\n",
    "#Calculate positive precision\n",
    "k_NN_positive_precision = k_NN_true_positive / (k_NN_true_positive + k_NN_false_positive)\n",
    "print('The positive precision for the k-NN model in the validation partition is',k_NN_positive_precision)\n",
    "\n",
    "#Calculate positive recall\n",
    "k_NN_positive_recall = k_NN_true_positive / (k_NN_true_positive + k_NN_false_negative)\n",
    "print('The positive recall for the k-NN model in the validation partition is',k_NN_positive_recall)\n",
    "\n",
    "#Calculate F score\n",
    "k_NN_F_score = (2 * k_NN_positive_precision * k_NN_positive_recall) / (k_NN_positive_precision + k_NN_positive_recall)\n",
    "print('The F-score for the k-NN model in the validation partition is',k_NN_F_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Tree (data standardization does not matter, though our data is already standardized at this point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model in the Validation Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best pruned tree in the validation partition is of depth 5\n",
      "The AUC of the best pruned tree in the validation partition is 0.8872916112920872\n"
     ]
    }
   ],
   "source": [
    "#Establish, for Python's sake, the independent and dependent variables\n",
    "DV = 'Manual Classification'\n",
    "y = non_test_data[DV]\n",
    "x = non_test_data.drop(columns = [DV])\n",
    "\n",
    "# Run Classification tree with k-fold cross validation with k=5\n",
    "kfolds = 5\n",
    "\n",
    "# Here we specify within which range of depths we will search for the best pruned tree\n",
    "maximum_depth = 100\n",
    "minimum_depth = 1\n",
    "parameter_grid = {'max_depth': list(range(minimum_depth, maximum_depth + 1))}\n",
    "\n",
    "classification_tree = GridSearchCV(DecisionTreeClassifier(criterion='entropy', random_state=1), parameter_grid, scoring='roc_auc', cv=kfolds, n_jobs=-1)\n",
    "classification_tree.fit(x,y)\n",
    "best_pruned_tree = classification_tree.best_estimator_\n",
    "\n",
    "# Display the level of depth of the best pruned tree\n",
    "print('The best pruned tree in the validation partition is of depth',best_pruned_tree.get_depth())\n",
    "\n",
    "# predict probabilities\n",
    "classification_tree_predicted_probabilities_validation_partition = best_pruned_tree.predict_proba(x)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "classification_tree_predicted_probabilities_validation_partition = classification_tree_predicted_probabilities_validation_partition[:, 1]\n",
    "\n",
    "# calculate AUC\n",
    "AUC_classification_tree_validation_partition = roc_auc_score(y, classification_tree_predicted_probabilities_validation_partition)\n",
    "print('The AUC of the best pruned tree in the validation partition is', AUC_classification_tree_validation_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model in the Test Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best pruned tree in the test partition is of depth 3\n",
      "The AUC of the best pruned tree in the test partition is 0.8772020168831826\n"
     ]
    }
   ],
   "source": [
    "#Establish, for Python's sake, the independent and dependent variables\n",
    "DV = 'Manual Classification'\n",
    "y2 = test_data[DV]\n",
    "x2 = test_data.drop(columns = [DV])\n",
    "\n",
    "# Run Classification tree with k-fold cross test with k=5\n",
    "kfolds = 5\n",
    "\n",
    "# Here we specify within which range of depths we will search for the best pruned tree\n",
    "maximum_depth = 100\n",
    "minimum_depth = 1\n",
    "parameter_grid = {'max_depth': list(range(minimum_depth, maximum_depth + 1))}\n",
    "\n",
    "classification_tree_2 = GridSearchCV(DecisionTreeClassifier(criterion='entropy', random_state=1), parameter_grid, scoring='roc_auc', cv=kfolds, n_jobs=-1)\n",
    "classification_tree_2.fit(x2,y2)\n",
    "best_pruned_tree_2 = classification_tree_2.best_estimator_\n",
    "\n",
    "# Display the level of depth of the best pruned tree\n",
    "print('The best pruned tree in the test partition is of depth',best_pruned_tree_2.get_depth())\n",
    "\n",
    "# predict probabilities\n",
    "classification_tree_predicted_probabilities_test_partition = best_pruned_tree_2.predict_proba(x2)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "classification_tree_predicted_probabilities_test_partition = classification_tree_predicted_probabilities_test_partition[:, 1]\n",
    "\n",
    "# calculate AUC\n",
    "AUC_classification_tree_test_partition = roc_auc_score(y2, classification_tree_predicted_probabilities_test_partition)\n",
    "print('The AUC of the best pruned tree in the test partition is', AUC_classification_tree_test_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Tree Confusion Matrix (validation partition)\n",
    "\n",
    "#### Note: since we are dealing with flagging depression, we are most concerned with capturing all True Positives and avoiding False Negatives, since we want to help people to are depressed (capture True Positives) and avoid accidentally ignoring people who are depressed (avoid False Negatives). Thus, we want to measure positive precision and positive recall together as the F-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The positive precision for the classification tree model in the validation partition is 0.8568738229755178\n",
      "The positive recall for the classification tree model in the validation partition is 0.866254164683484\n",
      "The F-score for the classification tree model in the validation partition is 0.8615384615384615\n"
     ]
    }
   ],
   "source": [
    "#convert predicted probabilties into 1s and 0s\n",
    "y_predicted_classification_tree = []\n",
    "for i in classification_tree_predicted_probabilities_validation_partition:\n",
    "    if i >= .5:\n",
    "        y_predicted_classification_tree.append(1)\n",
    "    else:\n",
    "        y_predicted_classification_tree.append(0)\n",
    "        \n",
    "#create confusion matrix: confusion_matrix(y_true, y_pred)\n",
    "#Note from sci-k itlearn.org:\n",
    "#Thus in binary classification, the count of true negatives is M[0,0], false negatives is M[1,0], \n",
    "    #true positives is M[1,1], and false positives is M[0,1].\n",
    "classification_tree_confusion_matrix = confusion_matrix(y,y_predicted_classification_tree)\n",
    "\n",
    "classification_tree_true_positive = classification_tree_confusion_matrix[1,1]\n",
    "classification_tree_true_negative = classification_tree_confusion_matrix[0,0]\n",
    "classification_tree_false_positive = classification_tree_confusion_matrix[0,1]\n",
    "classification_tree_false_negative = classification_tree_confusion_matrix[1,0]\n",
    "\n",
    "#Calculate positive precision\n",
    "classification_tree_positive_precision = classification_tree_true_positive / (classification_tree_true_positive + classification_tree_false_positive)\n",
    "print('The positive precision for the classification tree model in the validation partition is',classification_tree_positive_precision)\n",
    "\n",
    "#Calculate positive recall\n",
    "classification_tree_positive_recall = classification_tree_true_positive / (classification_tree_true_positive + classification_tree_false_negative)\n",
    "print('The positive recall for the classification tree model in the validation partition is',classification_tree_positive_recall)\n",
    "\n",
    "#Calculate F score\n",
    "classification_tree_F_score = (2 * classification_tree_positive_precision * classification_tree_positive_recall) / (classification_tree_positive_precision + classification_tree_positive_recall)\n",
    "print('The F-score for the classification tree model in the validation partition is',classification_tree_F_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model in the validation partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC for the random forest model in the validation partition is 0.9992806455800268\n"
     ]
    }
   ],
   "source": [
    "#Establish, for Python's sake, the independent and dependent variables\n",
    "DV = 'Manual Classification'\n",
    "y = non_test_data[DV]\n",
    "x = non_test_data.drop(columns = [DV])\n",
    "\n",
    "# Run Random Forest with k-fold cross validation with k=5\n",
    "kfolds = 5\n",
    "\n",
    "#Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 3)]\n",
    "\n",
    "#Number of features to consider at every split\n",
    "#From the Random Forest Python documentation: \n",
    "    #Empirical good default values are max_features=sqrt(n_features) for classification tasks\n",
    "    #This translates to the 'sqrt' default option that the model contains\n",
    "max_features = ['sqrt']\n",
    "\n",
    "#Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 3)]\n",
    "max_depth.append(None)\n",
    "\n",
    "#Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "#Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "#Create the random grid, and run the classifier on our x and y\n",
    "param_grid = {'n_estimators': n_estimators,'max_features': max_features,'max_depth': max_depth,\n",
    "              'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "grid_cv = GridSearchCV(rf, param_grid, scoring = 'roc_auc', cv = kfolds, n_jobs=-1)\n",
    "grid_cv.fit(x, y)\n",
    "\n",
    "random_forest_classifier_optimal_validation_partition = grid_cv.best_estimator_\n",
    "\n",
    "# predict probabilities using the classifier and keep probabilities for the positive outcome only\n",
    "random_forest_predicted_probabilities_validation_partition = random_forest_classifier_optimal_validation_partition.predict_proba(x)[:,1]\n",
    "\n",
    "# Get the AUC of the best Random Forest Classifier\n",
    "AUC_random_forest_validation_partition = roc_auc_score(y, random_forest_predicted_probabilities_validation_partition)\n",
    "print('The AUC for the random forest model in the validation partition is', AUC_random_forest_validation_partition )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model in the test partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC for the random forest model in the test partition is 0.9915584087347723\n"
     ]
    }
   ],
   "source": [
    "#Establish, for Python's sake, the independent and dependent variables\n",
    "DV = 'Manual Classification'\n",
    "y2 = test_data[DV]\n",
    "x2 = test_data.drop(columns = [DV])\n",
    "\n",
    "# Run Random Forest with k-fold cross test with k=5\n",
    "kfolds = 5\n",
    "\n",
    "#Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 3)]\n",
    "\n",
    "#Number of features to consider at every split\n",
    "#From the Random Forest Python documentation: \n",
    "    #Empirical good default values are max_features=sqrt(n_features) for classification tasks\n",
    "    #This translates to the 'sqrt' default option that the model contains\n",
    "max_features = ['sqrt']\n",
    "\n",
    "#Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 3)]\n",
    "max_depth.append(None)\n",
    "\n",
    "#Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "#Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "#Create the random grid, and run the classifier on our x and y\n",
    "param_grid = {'n_estimators': n_estimators,'max_features': max_features,'max_depth': max_depth,\n",
    "              'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "grid_cv = GridSearchCV(rf, param_grid, scoring = 'roc_auc', cv = kfolds, n_jobs=-1)\n",
    "grid_cv.fit(x2, y2)\n",
    "\n",
    "random_forest_classifier_optimal_test_partition = grid_cv.best_estimator_\n",
    "\n",
    "# predict probabilities using the classifier and keep probabilities for the positive outcome only\n",
    "random_forest_predicted_probabilities_test_partition = random_forest_classifier_optimal_test_partition.predict_proba(x2)[:,1]\n",
    "\n",
    "#Get the AUC of the best Random Forest Classifier\n",
    "AUC_random_forest_test_partition = roc_auc_score(y2, random_forest_predicted_probabilities_test_partition)\n",
    "print('The AUC for the random forest model in the test partition is', AUC_random_forest_test_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Confusion Matrix (validation partition)\n",
    "\n",
    "#### Note: since we are dealing with flagging depression, we are most concerned with capturing all True Positives and avoiding False Negatives, since we want to help people to are depressed (capture True Positives) and avoid accidentally ignoring people who are depressed (avoid False Negatives). Thus, we want to measure positive precision and positive recall together as the F-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The positive precision for the random forest model in the validation partition is 0.9775386055217595\n",
      "The positive recall for the random forest model in the validation partition is 0.99428843407901\n",
      "The F-score for the random forest model in the validation partition is 0.9858423784804153\n"
     ]
    }
   ],
   "source": [
    "#convert predicted probabilties into 1s and 0s\n",
    "y_predicted_random_forest = []\n",
    "for i in random_forest_predicted_probabilities_validation_partition:\n",
    "    if i >= .5:\n",
    "        y_predicted_random_forest.append(1)\n",
    "    else:\n",
    "        y_predicted_random_forest.append(0)\n",
    "        \n",
    "#create confusion matrix: confusion_matrix(y_true, y_pred)\n",
    "#Note from sci-k itlearn.org:\n",
    "#Thus in binary classification, the count of true negatives is M[0,0], false negatives is M[1,0], \n",
    "    #true positives is M[1,1], and false positives is M[0,1].\n",
    "random_forest_confusion_matrix = confusion_matrix(y,y_predicted_random_forest)\n",
    "\n",
    "random_forest_true_positive = random_forest_confusion_matrix[1,1]\n",
    "random_forest_true_negative = random_forest_confusion_matrix[0,0]\n",
    "random_forest_false_positive = random_forest_confusion_matrix[0,1]\n",
    "random_forest_false_negative = random_forest_confusion_matrix[1,0]\n",
    "\n",
    "#Calculate positive precision\n",
    "random_forest_positive_precision = random_forest_true_positive / (random_forest_true_positive + random_forest_false_positive)\n",
    "print('The positive precision for the random forest model in the validation partition is',random_forest_positive_precision)\n",
    "\n",
    "#Calculate positive recall\n",
    "random_forest_positive_recall = random_forest_true_positive / (random_forest_true_positive + random_forest_false_negative)\n",
    "print('The positive recall for the random forest model in the validation partition is',random_forest_positive_recall)\n",
    "\n",
    "#Calculate F score\n",
    "random_forest_F_score = (2 * random_forest_positive_precision * random_forest_positive_recall) / (random_forest_positive_precision + random_forest_positive_recall)\n",
    "print('The F-score for the random forest model in the validation partition is',random_forest_F_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model in the validation partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC for the adaboost model in the validation partition is 1.0\n"
     ]
    }
   ],
   "source": [
    "#Establish, for Python's sake, the independent and dependent variables\n",
    "DV = 'Manual Classification'\n",
    "y = non_test_data[DV]\n",
    "x = non_test_data.drop(columns = [DV])\n",
    "\n",
    "# Run Random Forest with k-fold cross validation with k=5\n",
    "kfolds = 5\n",
    "\n",
    "#Set a parameter grid for the GridSearchCV\n",
    "param_grid = {\"base_estimator__criterion\": [\"gini\", \"entropy\"], \"base_estimator__splitter\": [\"best\", \"random\"], \n",
    "              \"n_estimators\": [10, 50, 100, 500]}\n",
    "\n",
    "#Assigning models and functions\n",
    "DTC = DecisionTreeClassifier(random_state = 1, max_features = \"auto\", max_depth = 10)\n",
    "adaboost = AdaBoostClassifier(base_estimator = DTC, random_state=1)\n",
    "\n",
    "#Use a GridSearchCV to find the optimal model candidate\n",
    "grid_cv = GridSearchCV(adaboost, param_grid, scoring = 'roc_auc', cv = kfolds, n_jobs=-1)\n",
    "grid_cv.fit(x, y)\n",
    "adaboost_classifier_optimal_validation_partition = grid_cv.best_estimator_\n",
    "\n",
    "# predict probabilities using the classifier and keep probabilities for the positive outcome only\n",
    "adaboost_predicted_probabilities_validation_partition = adaboost_classifier_optimal_validation_partition.predict_proba(x)[:,1]\n",
    "\n",
    "# Get the AUC of the best ADA Boost - test\n",
    "AUC_adaboost_validation_partition = roc_auc_score(y, adaboost_predicted_probabilities_validation_partition)\n",
    "print('The AUC for the adaboost model in the validation partition is', AUC_adaboost_validation_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model in the test partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC for the adaboost model in the test partition is 1.0\n"
     ]
    }
   ],
   "source": [
    "#Establish, for Python's sake, the independent and dependent variables\n",
    "DV = 'Manual Classification'\n",
    "y2 = test_data[DV]\n",
    "x2 = test_data.drop(columns = [DV])\n",
    "\n",
    "# Run Random Forest with k-fold cross test with k=5\n",
    "kfolds = 5\n",
    "\n",
    "#Set a parameter grid for the GridSearchCV\n",
    "param_grid = {\"base_estimator__criterion\": [\"gini\", \"entropy\"], \"base_estimator__splitter\": [\"best\", \"random\"], \n",
    "              \"n_estimators\": [10, 50, 100, 500]}\n",
    "\n",
    "#Assigning models and functions\n",
    "DTC = DecisionTreeClassifier(random_state = 1, max_features = \"auto\", max_depth = 10)\n",
    "adaboost = AdaBoostClassifier(base_estimator = DTC, random_state=1)\n",
    "\n",
    "#Use a GridSearchCV to find the optimal model candidate\n",
    "grid_cv = GridSearchCV(adaboost, param_grid, scoring = 'roc_auc', cv = kfolds, n_jobs=-1)\n",
    "grid_cv.fit(x2, y2)\n",
    "adaboost_classifier_optimal_test_partition = grid_cv.best_estimator_\n",
    "\n",
    "# predict probabilities using the classifier and keep probabilities for the positive outcome only\n",
    "adaboost_predicted_probabilities_test_partition = adaboost_classifier_optimal_test_partition.predict_proba(x2)[:,1]\n",
    "\n",
    "# Get the AUC of the best ADA Boost - test\n",
    "AUC_adaboost_test_partition = roc_auc_score(y2, adaboost_predicted_probabilities_test_partition)\n",
    "print('The AUC for the adaboost model in the test partition is', AUC_adaboost_test_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Confusion Matrix (validation partition)\n",
    "\n",
    "#### Note: since we are dealing with flagging depression, we are most concerned with capturing all True Positives and avoiding False Negatives, since we want to help people to are depressed (capture True Positives) and avoid accidentally ignoring people who are depressed (avoid False Negatives). Thus, we want to measure positive precision and positive recall together as the F-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The positive precision for the adaboost model in the validation partition is 1.0\n",
      "The positive recall for the adaboost model in the validation partition is 1.0\n",
      "The F-score for the adaboost model in the validation partition is 1.0\n"
     ]
    }
   ],
   "source": [
    "#convert predicted probabilties into 1s and 0s\n",
    "y_predicted_adaboost = []\n",
    "for i in adaboost_predicted_probabilities_validation_partition:\n",
    "    if i >= .5:\n",
    "        y_predicted_adaboost.append(1)\n",
    "    else:\n",
    "        y_predicted_adaboost.append(0)\n",
    "        \n",
    "#create confusion matrix: confusion_matrix(y_true, y_pred)\n",
    "#Note from sci-k itlearn.org:\n",
    "#Thus in binary classification, the count of true negatives is M[0,0], false negatives is M[1,0], \n",
    "    #true positives is M[1,1], and false positives is M[0,1].\n",
    "adaboost_confusion_matrix = confusion_matrix(y,y_predicted_adaboost)\n",
    "\n",
    "adaboost_true_positive = adaboost_confusion_matrix[1,1]\n",
    "adaboost_true_negative = adaboost_confusion_matrix[0,0]\n",
    "adaboost_false_positive = adaboost_confusion_matrix[0,1]\n",
    "adaboost_false_negative = adaboost_confusion_matrix[1,0]\n",
    "\n",
    "#Calculate positive precision\n",
    "adaboost_positive_precision = adaboost_true_positive / (adaboost_true_positive + adaboost_false_positive)\n",
    "print('The positive precision for the adaboost model in the validation partition is',adaboost_positive_precision)\n",
    "\n",
    "#Calculate positive recall\n",
    "adaboost_positive_recall = adaboost_true_positive / (adaboost_true_positive + adaboost_false_negative)\n",
    "print('The positive recall for the adaboost model in the validation partition is',adaboost_positive_recall)\n",
    "\n",
    "#Calculate F score\n",
    "adaboost_F_score = (2 * adaboost_positive_precision * adaboost_positive_recall) / (adaboost_positive_precision + adaboost_positive_recall)\n",
    "print('The F-score for the adaboost model in the validation partition is',adaboost_F_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataframe of overall results for easy viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Names</th>\n",
       "      <th>AUC in Validation Partition</th>\n",
       "      <th>AUC in Test Partition</th>\n",
       "      <th>Positive Precision</th>\n",
       "      <th>Positive Recall</th>\n",
       "      <th>F-Score</th>\n",
       "      <th>Ratio of AUC in Test Partition to AUC in Validation Partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.872461</td>\n",
       "      <td>0.879297</td>\n",
       "      <td>0.834252</td>\n",
       "      <td>0.864826</td>\n",
       "      <td>0.849264</td>\n",
       "      <td>1.007835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k-NN</td>\n",
       "      <td>0.892793</td>\n",
       "      <td>0.891378</td>\n",
       "      <td>0.858441</td>\n",
       "      <td>0.854355</td>\n",
       "      <td>0.856393</td>\n",
       "      <td>0.998415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Classification Tree</td>\n",
       "      <td>0.887292</td>\n",
       "      <td>0.877202</td>\n",
       "      <td>0.856874</td>\n",
       "      <td>0.866254</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.988629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.999281</td>\n",
       "      <td>0.991558</td>\n",
       "      <td>0.977539</td>\n",
       "      <td>0.994288</td>\n",
       "      <td>0.985842</td>\n",
       "      <td>0.992272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model Names  AUC in Validation Partition  AUC in Test Partition  \\\n",
       "0  Logistic Regression                     0.872461               0.879297   \n",
       "1                 k-NN                     0.892793               0.891378   \n",
       "2  Classification Tree                     0.887292               0.877202   \n",
       "3        Random Forest                     0.999281               0.991558   \n",
       "4             AdaBoost                     1.000000               1.000000   \n",
       "\n",
       "   Positive Precision  Positive Recall   F-Score  \\\n",
       "0            0.834252         0.864826  0.849264   \n",
       "1            0.858441         0.854355  0.856393   \n",
       "2            0.856874         0.866254  0.861538   \n",
       "3            0.977539         0.994288  0.985842   \n",
       "4            1.000000         1.000000  1.000000   \n",
       "\n",
       "   Ratio of AUC in Test Partition to AUC in Validation Partition  \n",
       "0                                           1.007835              \n",
       "1                                           0.998415              \n",
       "2                                           0.988629              \n",
       "3                                           0.992272              \n",
       "4                                           1.000000              "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names = ['Logistic Regression', 'k-NN', 'Classification Tree', 'Random Forest', 'AdaBoost']\n",
    "\n",
    "AUC_in_validation_partition = [AUC_logistic_regression_validation_partition,\n",
    "                              AUC_k_NN_validation_partition,\n",
    "                              AUC_classification_tree_validation_partition,\n",
    "                              AUC_random_forest_validation_partition,\n",
    "                              AUC_adaboost_validation_partition]\n",
    "\n",
    "AUC_in_test_partition = [AUC_logistic_regression_test_partition,\n",
    "                              AUC_k_NN_test_partition,\n",
    "                              AUC_classification_tree_test_partition,\n",
    "                              AUC_random_forest_test_partition,\n",
    "                              AUC_adaboost_test_partition]\n",
    "\n",
    "positive_precision = [logistic_regression_positive_precision,\n",
    "                      k_NN_positive_precision,\n",
    "                      classification_tree_positive_precision,\n",
    "                      random_forest_positive_precision,\n",
    "                      adaboost_positive_precision]\n",
    "\n",
    "positive_recall = [logistic_regression_positive_recall,\n",
    "                      k_NN_positive_recall,\n",
    "                      classification_tree_positive_recall,\n",
    "                      random_forest_positive_recall,\n",
    "                      adaboost_positive_recall]\n",
    "\n",
    "F_score = [logistic_regression_F_score,\n",
    "                      k_NN_F_score,\n",
    "                      classification_tree_F_score,\n",
    "                      random_forest_F_score,\n",
    "                      adaboost_F_score]\n",
    "summary_data = ({'Model Names': model_names, \n",
    "                 'AUC in Validation Partition': AUC_in_validation_partition,\n",
    "                'AUC in Test Partition': AUC_in_test_partition,\n",
    "                'Positive Precision': positive_precision,\n",
    "                'Positive Recall': positive_recall,\n",
    "                'F-Score': F_score})\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "#Add one more column to compare validation and test partitions to guard against overfitting\n",
    "summary_df['Ratio of AUC in Test Partition to AUC in Validation Partition'] = summary_df['AUC in Test Partition'] / summary_df['AUC in Validation Partition']\n",
    "\n",
    "summary_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For final report purposes, bring relevant AdaBoost metrics to the bottom for easy finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Adaboost model accuracy on the original data in the validation partition is 1.0\n",
      "The F-score for the adaboost model on the orginal data in the validation partition is 1.0\n",
      "The false negative rate for the adaboost model on the orginal data in the validation partition is 0.0\n"
     ]
    }
   ],
   "source": [
    "#AdaBoost accuracy\n",
    "adaboost_accuracy = (adaboost_true_positive + adaboost_true_negative) / (adaboost_true_positive + adaboost_true_negative + adaboost_false_positive + adaboost_false_negative)\n",
    "print('The Adaboost model accuracy on the original data in the validation partition is', adaboost_accuracy)\n",
    "\n",
    "#Adaboost F-score\n",
    "print('The F-score for the adaboost model on the orginal data in the validation partition is',adaboost_F_score)\n",
    "\n",
    "#AdaBoost false negative rate\n",
    "adaboost_false_negative_rate = adaboost_false_negative / (adaboost_false_negative + adaboost_true_positive)\n",
    "print('The false negative rate for the adaboost model on the orginal data in the validation partition is',adaboost_false_negative_rate)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
