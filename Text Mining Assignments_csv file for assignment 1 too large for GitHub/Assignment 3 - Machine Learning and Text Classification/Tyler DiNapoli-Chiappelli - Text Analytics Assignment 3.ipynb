{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB # import naive bayes\n",
    "from sklearn.naive_bayes import MultinomialNB# import naive bayes\n",
    "from sklearn.tree import DecisionTreeClassifier # import Decision Tree\n",
    "from sklearn.ensemble import RandomForestClassifier # import random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Spam Email.csv\", usecols=[\"CATEGORY\", \"MESSAGE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing (taken directly from Lab 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>MESSAGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>dear homeown interest rate are at their lowest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>attent thi is a must for all comput user new s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>thi is a multi part messag in mime format next...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>import inform the new domain name are final av...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>thi is the bottom line If you can give away CD...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CATEGORY                                            MESSAGE\n",
       "0         1  dear homeown interest rate are at their lowest...\n",
       "1         1  attent thi is a must for all comput user new s...\n",
       "2         1  thi is a multi part messag in mime format next...\n",
       "3         1  import inform the new domain name are final av...\n",
       "4         1  thi is the bottom line If you can give away CD..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove non alphabetical characters\n",
    "remove_non_alphabets = lambda x: re.sub(r'[^a-zA-Z]',' ',x)\n",
    "\n",
    "# tokenn alphabets-only list\n",
    "tokenize = lambda x: word_tokenize(x)\n",
    "\n",
    "# assign Porter Stemmer to a lambda function to run on each line of value\n",
    "Porter_Stemmer = PorterStemmer()\n",
    "stem = lambda w: [ Porter_Stemmer.stem(x) for x in w ]\n",
    "\n",
    "# assign lemmatizer to a lambda function to run on each line of value\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatizer_2 = lambda x: [ lemmatizer.lemmatize(word) for word in x ]\n",
    "\n",
    "# apply all above methods to the MESSAGE column\n",
    "data['MESSAGE'] = data['MESSAGE'].apply(remove_non_alphabets)\n",
    "data['MESSAGE'] = data['MESSAGE'].apply(tokenize)\n",
    "data['MESSAGE'] = data['MESSAGE'].apply(stem)\n",
    "data['MESSAGE'] = data['MESSAGE'].apply(lemmatizer_2)\n",
    "data['MESSAGE'] = data['MESSAGE'].apply(lambda x: ' '.join(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into simple training and test sets, per the HW instructions (taken directly from Lab 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into 30 percent test data and 70 percent training data\n",
    "train_corpus, test_corpus, train_labels, test_labels = train_test_split(data[\"MESSAGE\"], data[\"CATEGORY\"], test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of features for Machine Learning models (taken directly from Lab 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words (\"BoW\" for short; \"binary\", in the words of the homework assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build bag of words features' vectorizer and get features\n",
    "BoW_vectorizer=CountVectorizer(min_df=1, ngram_range=(1,1))\n",
    "BoW_train_features = BoW_vectorizer.fit_transform(train_corpus)\n",
    "BoW_test_features = BoW_vectorizer.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build tfidf features' vectorizer and get features\n",
    "tfidf_vectorizer=TfidfVectorizer(min_df=1, norm='l2', smooth_idf=True, use_idf=True, ngram_range=(1,1))\n",
    "\n",
    "tfidf_train_features = tfidf_vectorizer.fit_transform(train_corpus)  \n",
    "tfidf_test_features = tfidf_vectorizer.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec (\"frequency\", in the words of the homework assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize documents for word2vec\n",
    "tokenized_train = [nltk.word_tokenize(text)\n",
    "                   for text in train_corpus]\n",
    "tokenized_test = [nltk.word_tokenize(text)\n",
    "                   for text in test_corpus]  \n",
    "\n",
    "# build word2vec model                   \n",
    "wv_model = gensim.models.Word2Vec(tokenized_train,\n",
    "                               vector_size=200,                          #set the size or dimension for the word vectors \n",
    "                               window=60,                        #specify the length of the window of words taken as context\n",
    "                               min_count=10)                   #ignores all words with total frequency lower than 10\n",
    "\n",
    "def average_word_vectors(words, model, vocabulary, num_features):\n",
    "    \n",
    "    feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
    "    nwords = 0.\n",
    "    \n",
    "    for word in words:\n",
    "        if word in vocabulary: \n",
    "            nwords = nwords + 1.\n",
    "            feature_vector = np.add(feature_vector, model.wv[word])\n",
    "    \n",
    "    if nwords:\n",
    "        feature_vector = np.divide(feature_vector, nwords)\n",
    "        \n",
    "    return feature_vector \n",
    "   \n",
    "\n",
    "def averaged_word_vectorizer(corpus, model, num_features):\n",
    "    vocabulary = set(model.wv.index_to_key)\n",
    "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
    "                    for tokenized_sentence in corpus]\n",
    "    return np.array(features)\n",
    "\n",
    "# averaged word vector features from word2vec\n",
    "avg_wv_train_features = averaged_word_vectorizer(corpus=tokenized_train,\n",
    "                                                 model=wv_model,\n",
    "                                                 num_features=200)                   \n",
    "avg_wv_test_features = averaged_word_vectorizer(corpus=tokenized_test,\n",
    "                                                model=wv_model,\n",
    "                                                num_features=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a function for training and testing models (taken directly from Lab 3, with a minor modification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that trains the model, performs predictions and evaluates the predictions\n",
    "def train_predict_model(classifier, train_features, train_labels, test_features):\n",
    "    \n",
    "    # build model    \n",
    "    classifier.fit(train_features, train_labels)\n",
    "    \n",
    "    # predict using model and return predictions\n",
    "    predictions = classifier.predict(test_features) \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Models on Bag of Words Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes model (\"NB\" for short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test model (taken directly from Lab 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign naive bayes function to an object\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# predict and evaluate naive bayes\n",
    "mnb_BoW_predictions = train_predict_model(classifier = mnb, train_features = BoW_train_features, train_labels = train_labels,\n",
    "                                           test_features = BoW_test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Confusion Matrix for the Naive Bayes model with Bag of Words features:\n",
      " [[1164    6]\n",
      " [ 130  439]]\n",
      "\n",
      "The positive precision for the Naive Bayes model with Bag of Words features is 0.99\n",
      "The negative precision for the Naive Bayes model with Bag of Words features is 0.9\n",
      "The positive recall for the Naive Bayes model with Bag of Words features is 0.77\n",
      "The negative recall for the Naive Bayes model with Bag of Words features is 0.99\n"
     ]
    }
   ],
   "source": [
    "#Count the predicted one and zeros and the actual ones and zeros\n",
    "#confusion_matrix(y_true, y_pred)\n",
    "\n",
    "#Note from sci-k itlearn.org:\n",
    "#Thus in binary classification, the count of true negatives is M[0,0], false negatives is M[1,0], \n",
    "    #true positives is M[1,1], and false positives is M[0,1] .\n",
    "NB_BoW_confusion_matrix = confusion_matrix(test_labels, mnb_BoW_predictions)\n",
    "\n",
    "NB_BoW_true_positive = NB_BoW_confusion_matrix[1,1]\n",
    "NB_BoW_true_negative = NB_BoW_confusion_matrix[0,0]\n",
    "NB_BoW_false_positive = NB_BoW_confusion_matrix[0,1]\n",
    "NB_BoW_false_negative = NB_BoW_confusion_matrix[1,0]\n",
    "\n",
    "print('This is the Confusion Matrix for the Naive Bayes model with Bag of Words features:\\n', NB_BoW_confusion_matrix)\n",
    "\n",
    "#Calculate positive precision\n",
    "NB_BoW_positive_precision = round(NB_BoW_true_positive / (NB_BoW_true_positive + NB_BoW_false_positive), 2)\n",
    "print('\\nThe positive precision for the Naive Bayes model with Bag of Words features is', NB_BoW_positive_precision)\n",
    "\n",
    "#Calculate negative precision\n",
    "NB_BoW_negative_precision = round(NB_BoW_true_negative / (NB_BoW_true_negative + NB_BoW_false_negative), 2)\n",
    "print('The negative precision for the Naive Bayes model with Bag of Words features is', NB_BoW_negative_precision)\n",
    "\n",
    "#Calculate positive recall\n",
    "NB_BoW_positive_recall = round(NB_BoW_true_positive / (NB_BoW_true_positive + NB_BoW_false_negative), 2)\n",
    "print('The positive recall for the Naive Bayes model with Bag of Words features is', NB_BoW_positive_recall)\n",
    "\n",
    "#Calculate negative recall\n",
    "NB_BoW_negative_recall = round(NB_BoW_true_negative / (NB_BoW_true_negative + NB_BoW_false_positive), 2)\n",
    "print('The negative recall for the Naive Bayes model with Bag of Words features is', NB_BoW_negative_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree (\"DT\" for short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test model (taken directly from Lab 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign decision tree function to an object\n",
    "DT = DecisionTreeClassifier()\n",
    "\n",
    "# predict and evaluate decision tree\n",
    "DT_BoW_predictions = train_predict_model(classifier=DT, train_features=BoW_train_features, train_labels=train_labels,\n",
    "                                         test_features=BoW_test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Confusion Matrix for the Decision Tree model with Bag of Words features:\n",
      " [[1125   45]\n",
      " [  40  529]]\n",
      "\n",
      "The positive precision for the Decision Tree model with Bag of Words features is 0.92\n",
      "The negative precision for the Decision Tree model with Bag of Words features is 0.97\n",
      "The positive recall for the Decision Tree model with Bag of Words features is 0.93\n",
      "The negative recall for the Decision Tree model with Bag of Words features is 0.96\n"
     ]
    }
   ],
   "source": [
    "#Count the predicted one and zeros and the actual ones and zeros\n",
    "#confusion_matrix(y_true, y_pred)\n",
    "\n",
    "#Note from sci-k itlearn.org:\n",
    "#Thus in binary classification, the count of true negatives is M[0,0], false negatives is M[1,0], \n",
    "    #true positives is M[1,1], and false positives is M[0,1] .\n",
    "DT_BoW_confusion_matrix = confusion_matrix(test_labels, DT_BoW_predictions)\n",
    "\n",
    "DT_BoW_true_positive = DT_BoW_confusion_matrix[1,1]\n",
    "DT_BoW_true_negative = DT_BoW_confusion_matrix[0,0]\n",
    "DT_BoW_false_positive = DT_BoW_confusion_matrix[0,1]\n",
    "DT_BoW_false_negative = DT_BoW_confusion_matrix[1,0]\n",
    "\n",
    "print('This is the Confusion Matrix for the Decision Tree model with Bag of Words features:\\n', DT_BoW_confusion_matrix)\n",
    "\n",
    "#Calculate positive precision\n",
    "DT_BoW_positive_precision = round(DT_BoW_true_positive / (DT_BoW_true_positive + DT_BoW_false_positive), 2)\n",
    "print('\\nThe positive precision for the Decision Tree model with Bag of Words features is', DT_BoW_positive_precision)\n",
    "\n",
    "#Calculate negative precision\n",
    "DT_BoW_negative_precision = round(DT_BoW_true_negative / (DT_BoW_true_negative + DT_BoW_false_negative), 2)\n",
    "print('The negative precision for the Decision Tree model with Bag of Words features is', DT_BoW_negative_precision)\n",
    "\n",
    "#Calculate positive recall\n",
    "DT_BoW_positive_recall = round(DT_BoW_true_positive / (DT_BoW_true_positive + DT_BoW_false_negative), 2)\n",
    "print('The positive recall for the Decision Tree model with Bag of Words features is', DT_BoW_positive_recall)\n",
    "\n",
    "#Calculate negative recall\n",
    "DT_BoW_negative_recall = round(DT_BoW_true_negative / (DT_BoW_true_negative + DT_BoW_false_positive), 2)\n",
    "print('The negative recall for the Decision Tree model with Bag of Words features is', DT_BoW_negative_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest model (\"RF\" for short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test model (taken directly from Lab 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign random forest function to an object\n",
    "RF = RandomForestClassifier(criterion=\"entropy\")\n",
    "\n",
    "# predict and evaluate random forest\n",
    "RF_BoW_predictions = train_predict_model(classifier=RF, train_features=BoW_train_features, train_labels=train_labels,\n",
    "                                         test_features=BoW_test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Confusion Matrix for the Random Forest model with Bag of Words features:\n",
      " [[1163    7]\n",
      " [  42  527]]\n",
      "\n",
      "The positive precision for the Random Forest model with Bag of Words features is 0.99\n",
      "The negative precision for the Random Forest model with Bag of Words features is 0.97\n",
      "The positive recall for the Random Forest model with Bag of Words features is 0.93\n",
      "The negative recall for the Random Forest model with Bag of Words features is 0.99\n"
     ]
    }
   ],
   "source": [
    "#Count the predicted one and zeros and the actual ones and zeros\n",
    "#confusion_matrix(y_true, y_pred)\n",
    "\n",
    "#Note from sci-k itlearn.org:\n",
    "#Thus in binary classification, the count of true negatives is M[0,0], false negatives is M[1,0], \n",
    "    #true positives is M[1,1], and false positives is M[0,1] .\n",
    "RF_BoW_confusion_matrix = confusion_matrix(test_labels, RF_BoW_predictions)\n",
    "\n",
    "RF_BoW_true_positive = RF_BoW_confusion_matrix[1,1]\n",
    "RF_BoW_true_negative = RF_BoW_confusion_matrix[0,0]\n",
    "RF_BoW_false_positive = RF_BoW_confusion_matrix[0,1]\n",
    "RF_BoW_false_negative = RF_BoW_confusion_matrix[1,0]\n",
    "\n",
    "print('This is the Confusion Matrix for the Random Forest model with Bag of Words features:\\n', RF_BoW_confusion_matrix)\n",
    "\n",
    "#Calculate positive precision\n",
    "RF_BoW_positive_precision = round(RF_BoW_true_positive / (RF_BoW_true_positive + RF_BoW_false_positive), 2)\n",
    "print('\\nThe positive precision for the Random Forest model with Bag of Words features is', RF_BoW_positive_precision)\n",
    "\n",
    "#Calculate negative precision\n",
    "RF_BoW_negative_precision = round(RF_BoW_true_negative / (RF_BoW_true_negative + RF_BoW_false_negative), 2)\n",
    "print('The negative precision for the Random Forest model with Bag of Words features is', RF_BoW_negative_precision)\n",
    "\n",
    "#Calculate positive recall\n",
    "RF_BoW_positive_recall = round(RF_BoW_true_positive / (RF_BoW_true_positive + RF_BoW_false_negative), 2)\n",
    "print('The positive recall for the Random Forest model with Bag of Words features is', RF_BoW_positive_recall)\n",
    "\n",
    "#Calculate negative recall\n",
    "RF_BoW_negative_recall = round(RF_BoW_true_negative / (RF_BoW_true_negative + RF_BoW_false_positive), 2)\n",
    "print('The negative recall for the Random Forest model with Bag of Words features is', RF_BoW_negative_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Models on TF-IDF Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes model (\"NB\" for short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test model (taken directly from Lab 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign naive bayes function to an object\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# predict and evaluate naive bayes\n",
    "mnb_tfidf_predictions = train_predict_model(classifier = mnb, train_features = tfidf_train_features, train_labels = train_labels,\n",
    "                                           test_features = tfidf_test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Confusion Matrix for the Naive Bayes model with TF-IDF features:\n",
      " [[1166    4]\n",
      " [ 203  366]]\n",
      "\n",
      "The positive precision for the Naive Bayes model with TF-IDF features is 0.99\n",
      "The negative precision for the Naive Bayes model with TF-IDF features is 0.85\n",
      "The positive recall for the Naive Bayes model with TF-IDF features is 0.64\n",
      "The negative recall for the Naive Bayes model with TF-IDF features is 1.0\n"
     ]
    }
   ],
   "source": [
    "#Count the predicted one and zeros and the actual ones and zeros\n",
    "#confusion_matrix(y_true, y_pred)\n",
    "\n",
    "#Note from sci-k itlearn.org:\n",
    "#Thus in binary classification, the count of true negatives is M[0,0], false negatives is M[1,0], \n",
    "    #true positives is M[1,1], and false positives is M[0,1] .\n",
    "NB_tfidf_confusion_matrix = confusion_matrix(test_labels, mnb_tfidf_predictions)\n",
    "\n",
    "NB_tfidf_true_positive = NB_tfidf_confusion_matrix[1,1]\n",
    "NB_tfidf_true_negative = NB_tfidf_confusion_matrix[0,0]\n",
    "NB_tfidf_false_positive = NB_tfidf_confusion_matrix[0,1]\n",
    "NB_tfidf_false_negative = NB_tfidf_confusion_matrix[1,0]\n",
    "\n",
    "print('This is the Confusion Matrix for the Naive Bayes model with TF-IDF features:\\n', NB_tfidf_confusion_matrix)\n",
    "\n",
    "#Calculate positive precision\n",
    "NB_tfidf_positive_precision = round(NB_tfidf_true_positive / (NB_tfidf_true_positive + NB_tfidf_false_positive), 2)\n",
    "print('\\nThe positive precision for the Naive Bayes model with TF-IDF features is', NB_tfidf_positive_precision)\n",
    "\n",
    "#Calculate negative precision\n",
    "NB_tfidf_negative_precision = round(NB_tfidf_true_negative / (NB_tfidf_true_negative + NB_tfidf_false_negative), 2)\n",
    "print('The negative precision for the Naive Bayes model with TF-IDF features is', NB_tfidf_negative_precision)\n",
    "\n",
    "#Calculate positive recall\n",
    "NB_tfidf_positive_recall = round(NB_tfidf_true_positive / (NB_tfidf_true_positive + NB_tfidf_false_negative), 2)\n",
    "print('The positive recall for the Naive Bayes model with TF-IDF features is', NB_tfidf_positive_recall)\n",
    "\n",
    "#Calculate negative recall\n",
    "NB_tfidf_negative_recall = round(NB_tfidf_true_negative / (NB_tfidf_true_negative + NB_tfidf_false_positive), 2)\n",
    "print('The negative recall for the Naive Bayes model with TF-IDF features is', NB_tfidf_negative_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree (\"DT\" for short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test model (taken directly from Lab 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign decision tree function to an object\n",
    "DT = DecisionTreeClassifier()\n",
    "\n",
    "# predict and evaluate decision tree\n",
    "DT_tfidf_predictions = train_predict_model(classifier=DT, train_features=tfidf_train_features, train_labels=train_labels,\n",
    "                                         test_features=tfidf_test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Confusion Matrix for the Decision Tree model with TF-IDF features:\n",
      " [[1133   37]\n",
      " [  42  527]]\n",
      "\n",
      "The positive precision for the Decision Tree model with TF-IDF features is 0.93\n",
      "The negative precision for the Decision Tree model with TF-IDF features is 0.96\n",
      "The positive recall for the Decision Tree model with TF-IDF features is 0.93\n",
      "The negative recall for the Decision Tree model with TF-IDF features is 0.97\n"
     ]
    }
   ],
   "source": [
    "#Count the predicted one and zeros and the actual ones and zeros\n",
    "#confusion_matrix(y_true, y_pred)\n",
    "\n",
    "#Note from sci-k itlearn.org:\n",
    "#Thus in binary classification, the count of true negatives is M[0,0], false negatives is M[1,0], \n",
    "    #true positives is M[1,1], and false positives is M[0,1] .\n",
    "DT_tfidf_confusion_matrix = confusion_matrix(test_labels, DT_tfidf_predictions)\n",
    "\n",
    "DT_tfidf_true_positive = DT_tfidf_confusion_matrix[1,1]\n",
    "DT_tfidf_true_negative = DT_tfidf_confusion_matrix[0,0]\n",
    "DT_tfidf_false_positive = DT_tfidf_confusion_matrix[0,1]\n",
    "DT_tfidf_false_negative = DT_tfidf_confusion_matrix[1,0]\n",
    "\n",
    "print('This is the Confusion Matrix for the Decision Tree model with TF-IDF features:\\n', DT_tfidf_confusion_matrix)\n",
    "\n",
    "#Calculate positive precision\n",
    "DT_tfidf_positive_precision = round(DT_tfidf_true_positive / (DT_tfidf_true_positive + DT_tfidf_false_positive), 2)\n",
    "print('\\nThe positive precision for the Decision Tree model with TF-IDF features is', DT_tfidf_positive_precision)\n",
    "\n",
    "#Calculate negative precision\n",
    "DT_tfidf_negative_precision = round(DT_tfidf_true_negative / (DT_tfidf_true_negative + DT_tfidf_false_negative), 2)\n",
    "print('The negative precision for the Decision Tree model with TF-IDF features is', DT_tfidf_negative_precision)\n",
    "\n",
    "#Calculate positive recall\n",
    "DT_tfidf_positive_recall = round(DT_tfidf_true_positive / (DT_tfidf_true_positive + DT_tfidf_false_negative), 2)\n",
    "print('The positive recall for the Decision Tree model with TF-IDF features is', DT_tfidf_positive_recall)\n",
    "\n",
    "#Calculate negative recall\n",
    "DT_tfidf_negative_recall = round(DT_tfidf_true_negative / (DT_tfidf_true_negative + DT_tfidf_false_positive), 2)\n",
    "print('The negative recall for the Decision Tree model with TF-IDF features is', DT_tfidf_negative_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest model (\"RF\" for short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test model (taken directly from Lab 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign random forest function to an object\n",
    "RF = RandomForestClassifier(criterion=\"entropy\")\n",
    "\n",
    "# predict and evaluate random forest\n",
    "RF_tfidf_predictions = train_predict_model(classifier=RF, train_features=tfidf_train_features, train_labels=train_labels,\n",
    "                                         test_features=tfidf_test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Confusion Matrix for the Random Forest model with TF-IDF features:\n",
      " [[1164    6]\n",
      " [  46  523]]\n",
      "\n",
      "The positive precision for the Random Forest model with TF-IDF features is 0.99\n",
      "The negative precision for the Random Forest model with TF-IDF features is 0.96\n",
      "The positive recall for the Random Forest model with TF-IDF features is 0.92\n",
      "The negative recall for the Random Forest model with TF-IDF features is 0.99\n"
     ]
    }
   ],
   "source": [
    "#Count the predicted one and zeros and the actual ones and zeros\n",
    "#confusion_matrix(y_true, y_pred)\n",
    "\n",
    "#Note from sci-k itlearn.org:\n",
    "#Thus in binary classification, the count of true negatives is M[0,0], false negatives is M[1,0], \n",
    "    #true positives is M[1,1], and false positives is M[0,1] .\n",
    "RF_tfidf_confusion_matrix = confusion_matrix(test_labels, RF_tfidf_predictions)\n",
    "\n",
    "RF_tfidf_true_positive = RF_tfidf_confusion_matrix[1,1]\n",
    "RF_tfidf_true_negative = RF_tfidf_confusion_matrix[0,0]\n",
    "RF_tfidf_false_positive = RF_tfidf_confusion_matrix[0,1]\n",
    "RF_tfidf_false_negative = RF_tfidf_confusion_matrix[1,0]\n",
    "\n",
    "print('This is the Confusion Matrix for the Random Forest model with TF-IDF features:\\n', RF_tfidf_confusion_matrix)\n",
    "\n",
    "#Calculate positive precision\n",
    "RF_tfidf_positive_precision = round(RF_tfidf_true_positive / (RF_tfidf_true_positive + RF_tfidf_false_positive), 2)\n",
    "print('\\nThe positive precision for the Random Forest model with TF-IDF features is', RF_tfidf_positive_precision)\n",
    "\n",
    "#Calculate negative precision\n",
    "RF_tfidf_negative_precision = round(RF_tfidf_true_negative / (RF_tfidf_true_negative + RF_tfidf_false_negative), 2)\n",
    "print('The negative precision for the Random Forest model with TF-IDF features is', RF_tfidf_negative_precision)\n",
    "\n",
    "#Calculate positive recall\n",
    "RF_tfidf_positive_recall = round(RF_tfidf_true_positive / (RF_tfidf_true_positive + RF_tfidf_false_negative), 2)\n",
    "print('The positive recall for the Random Forest model with TF-IDF features is', RF_tfidf_positive_recall)\n",
    "\n",
    "#Calculate negative recall\n",
    "RF_tfidf_negative_recall = round(RF_tfidf_true_negative / (RF_tfidf_true_negative + RF_tfidf_false_positive), 2)\n",
    "print('The negative recall for the Random Forest model with TF-IDF features is', RF_tfidf_negative_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Models on Word2Vec Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes model (\"NB\" for short) (Please note, per TA instructions, we should use the GaussianNB Python package for Word2Vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test model (taken directly from Lab 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign naive bayes function to an object\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# predict and evaluate naive bayes\n",
    "gnb_wv_predictions = train_predict_model(classifier = gnb, train_features = avg_wv_train_features, train_labels = train_labels,\n",
    "                                           test_features = avg_wv_test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Confusion Matrix for the Naive Bayes model with Word2Vec features:\n",
      " [[1125   45]\n",
      " [ 102  467]]\n",
      "\n",
      "The positive precision for the Naive Bayes model with Word2Vec features is 0.91\n",
      "The negative precision for the Naive Bayes model with Word2Vec features is 0.92\n",
      "The positive recall for the Naive Bayes model with Word2Vec features is 0.82\n",
      "The negative recall for the Naive Bayes model with Word2Vec features is 0.96\n"
     ]
    }
   ],
   "source": [
    "#Count the predicted one and zeros and the actual ones and zeros\n",
    "#confusion_matrix(y_true, y_pred)\n",
    "\n",
    "#Note from sci-k itlearn.org:\n",
    "#Thus in binary classification, the count of true negatives is M[0,0], false negatives is M[1,0], \n",
    "    #true positives is M[1,1], and false positives is M[0,1] .\n",
    "NB_wv_confusion_matrix = confusion_matrix(test_labels, gnb_wv_predictions)\n",
    "\n",
    "NB_wv_true_positive = NB_wv_confusion_matrix[1,1]\n",
    "NB_wv_true_negative = NB_wv_confusion_matrix[0,0]\n",
    "NB_wv_false_positive = NB_wv_confusion_matrix[0,1]\n",
    "NB_wv_false_negative = NB_wv_confusion_matrix[1,0]\n",
    "\n",
    "print('This is the Confusion Matrix for the Naive Bayes model with Word2Vec features:\\n', NB_wv_confusion_matrix)\n",
    "\n",
    "#Calculate positive precision\n",
    "NB_wv_positive_precision = round(NB_wv_true_positive / (NB_wv_true_positive + NB_wv_false_positive), 2)\n",
    "print('\\nThe positive precision for the Naive Bayes model with Word2Vec features is', NB_wv_positive_precision)\n",
    "\n",
    "#Calculate negative precision\n",
    "NB_wv_negative_precision = round(NB_wv_true_negative / (NB_wv_true_negative + NB_wv_false_negative), 2)\n",
    "print('The negative precision for the Naive Bayes model with Word2Vec features is', NB_wv_negative_precision)\n",
    "\n",
    "#Calculate positive recall\n",
    "NB_wv_positive_recall = round(NB_wv_true_positive / (NB_wv_true_positive + NB_wv_false_negative), 2)\n",
    "print('The positive recall for the Naive Bayes model with Word2Vec features is', NB_wv_positive_recall)\n",
    "\n",
    "#Calculate negative recall\n",
    "NB_wv_negative_recall = round(NB_wv_true_negative / (NB_wv_true_negative + NB_wv_false_positive), 2)\n",
    "print('The negative recall for the Naive Bayes model with Word2Vec features is', NB_wv_negative_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree (\"DT\" for short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test model (taken directly from Lab 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign decision tree function to an object\n",
    "DT = DecisionTreeClassifier()\n",
    "\n",
    "# predict and evaluate decision tree\n",
    "DT_wv_predictions = train_predict_model(classifier=DT, train_features=avg_wv_train_features, train_labels=train_labels,\n",
    "                                         test_features=avg_wv_test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Confusion Matrix for the Decision Tree model with Word2Vec features:\n",
      " [[1152   18]\n",
      " [  25  544]]\n",
      "\n",
      "The positive precision for the Decision Tree model with Word2Vec features is 0.97\n",
      "The negative precision for the Decision Tree model with Word2Vec features is 0.98\n",
      "The positive recall for the Decision Tree model with Word2Vec features is 0.96\n",
      "The negative recall for the Decision Tree model with Word2Vec features is 0.98\n"
     ]
    }
   ],
   "source": [
    "#Count the predicted one and zeros and the actual ones and zeros\n",
    "#confusion_matrix(y_true, y_pred)\n",
    "\n",
    "#Note from sci-k itlearn.org:\n",
    "#Thus in binary classification, the count of true negatives is M[0,0], false negatives is M[1,0], \n",
    "    #true positives is M[1,1], and false positives is M[0,1] .\n",
    "DT_wv_confusion_matrix = confusion_matrix(test_labels, DT_wv_predictions)\n",
    "\n",
    "DT_wv_true_positive = DT_wv_confusion_matrix[1,1]\n",
    "DT_wv_true_negative = DT_wv_confusion_matrix[0,0]\n",
    "DT_wv_false_positive = DT_wv_confusion_matrix[0,1]\n",
    "DT_wv_false_negative = DT_wv_confusion_matrix[1,0]\n",
    "\n",
    "print('This is the Confusion Matrix for the Decision Tree model with Word2Vec features:\\n', DT_wv_confusion_matrix)\n",
    "\n",
    "#Calculate positive precision\n",
    "DT_wv_positive_precision = round(DT_wv_true_positive / (DT_wv_true_positive + DT_wv_false_positive), 2)\n",
    "print('\\nThe positive precision for the Decision Tree model with Word2Vec features is', DT_wv_positive_precision)\n",
    "\n",
    "#Calculate negative precision\n",
    "DT_wv_negative_precision = round(DT_wv_true_negative / (DT_wv_true_negative + DT_wv_false_negative), 2)\n",
    "print('The negative precision for the Decision Tree model with Word2Vec features is', DT_wv_negative_precision)\n",
    "\n",
    "#Calculate positive recall\n",
    "DT_wv_positive_recall = round(DT_wv_true_positive / (DT_wv_true_positive + DT_wv_false_negative), 2)\n",
    "print('The positive recall for the Decision Tree model with Word2Vec features is', DT_wv_positive_recall)\n",
    "\n",
    "#Calculate negative recall\n",
    "DT_wv_negative_recall = round(DT_wv_true_negative / (DT_wv_true_negative + DT_wv_false_positive), 2)\n",
    "print('The negative recall for the Decision Tree model with Word2Vec features is', DT_wv_negative_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest model (\"RF\" for short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test model (taken directly from Lab 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign random forest function to an object\n",
    "RF = RandomForestClassifier(criterion=\"entropy\")\n",
    "\n",
    "# predict and evaluate random forest\n",
    "RF_wv_predictions = train_predict_model(classifier=RF, train_features=avg_wv_train_features, train_labels=train_labels,\n",
    "                                         test_features=avg_wv_test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Confusion Matrix for the Random Forest model with Word2Vec features:\n",
      " [[1161    9]\n",
      " [  15  554]]\n",
      "\n",
      "The positive precision for the Random Forest model with Word2Vec features is 0.98\n",
      "The negative precision for the Random Forest model with Word2Vec features is 0.99\n",
      "The positive recall for the Random Forest model with Word2Vec features is 0.97\n",
      "The negative recall for the Random Forest model with Word2Vec features is 0.99\n"
     ]
    }
   ],
   "source": [
    "#Count the predicted one and zeros and the actual ones and zeros\n",
    "#confusion_matrix(y_true, y_pred)\n",
    "\n",
    "#Note from sci-k itlearn.org:\n",
    "#Thus in binary classification, the count of true negatives is M[0,0], false negatives is M[1,0], \n",
    "    #true positives is M[1,1], and false positives is M[0,1] .\n",
    "RF_wv_confusion_matrix = confusion_matrix(test_labels, RF_wv_predictions)\n",
    "\n",
    "RF_wv_true_positive = RF_wv_confusion_matrix[1,1]\n",
    "RF_wv_true_negative = RF_wv_confusion_matrix[0,0]\n",
    "RF_wv_false_positive = RF_wv_confusion_matrix[0,1]\n",
    "RF_wv_false_negative = RF_wv_confusion_matrix[1,0]\n",
    "\n",
    "print('This is the Confusion Matrix for the Random Forest model with Word2Vec features:\\n', RF_wv_confusion_matrix)\n",
    "\n",
    "#Calculate positive precision\n",
    "RF_wv_positive_precision = round(RF_wv_true_positive / (RF_wv_true_positive + RF_wv_false_positive), 2)\n",
    "print('\\nThe positive precision for the Random Forest model with Word2Vec features is', RF_wv_positive_precision)\n",
    "\n",
    "#Calculate negative precision\n",
    "RF_wv_negative_precision = round(RF_wv_true_negative / (RF_wv_true_negative + RF_wv_false_negative), 2)\n",
    "print('The negative precision for the Random Forest model with Word2Vec features is', RF_wv_negative_precision)\n",
    "\n",
    "#Calculate positive recall\n",
    "RF_wv_positive_recall = round(RF_wv_true_positive / (RF_wv_true_positive + RF_wv_false_negative), 2)\n",
    "print('The positive recall for the Random Forest model with Word2Vec features is', RF_wv_positive_recall)\n",
    "\n",
    "#Calculate negative recall\n",
    "RF_wv_negative_recall = round(RF_wv_true_negative / (RF_wv_true_negative + RF_wv_false_positive), 2)\n",
    "print('The negative recall for the Random Forest model with Word2Vec features is', RF_wv_negative_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the business costs of email mis-classification.\n",
    "#### Per the rules laid out in the assignment, mis-classifying spam to non-spam (a false negative) costs 5 and mis-classifying non-spam to spam (a false positive) costs 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negative_cost = 5\n",
    "false_positive_cost = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models with Bag of Words features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Naive Bayes model with Bag of Words features has 130 false negatives and 6 false positives. At a cost of 5 units per false negative and 100 units per false positive, this model costs the business 1250 units.\n"
     ]
    }
   ],
   "source": [
    "NB_BoW_false_negative_cost = NB_BoW_false_negative * false_negative_cost\n",
    "NB_BoW_false_positive_cost = NB_BoW_false_positive * false_positive_cost\n",
    "\n",
    "NB_BoW_total_cost = NB_BoW_false_negative_cost + NB_BoW_false_positive_cost\n",
    "\n",
    "print('The Naive Bayes model with Bag of Words features has', NB_BoW_false_negative, 'false negatives and', NB_BoW_false_positive,\n",
    "     'false positives. At a cost of 5 units per false negative and 100 units per false positive, this model costs the business', NB_BoW_total_cost,'units.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Decision Tree model with Bag of Words features has 40 false negatives and 45 false positives. At a cost of 5 units per false negative and 100 units per false positive, this model costs the business 4700 units.\n"
     ]
    }
   ],
   "source": [
    "DT_BoW_false_negative_cost = DT_BoW_false_negative * false_negative_cost\n",
    "DT_BoW_false_positive_cost = DT_BoW_false_positive * false_positive_cost\n",
    "\n",
    "DT_BoW_total_cost = DT_BoW_false_negative_cost + DT_BoW_false_positive_cost\n",
    "\n",
    "print('The Decision Tree model with Bag of Words features has', DT_BoW_false_negative, 'false negatives and', DT_BoW_false_positive,\n",
    "     'false positives. At a cost of 5 units per false negative and 100 units per false positive, this model costs the business', DT_BoW_total_cost,'units.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Random Forest model with Bag of Words features has 42 false negatives and 7 false positives. At a cost of 5 units per false negative and 100 units per false positive, this model costs the business 910 units.\n"
     ]
    }
   ],
   "source": [
    "RF_BoW_false_negative_cost = RF_BoW_false_negative * false_negative_cost\n",
    "RF_BoW_false_positive_cost = RF_BoW_false_positive * false_positive_cost\n",
    "\n",
    "RF_BoW_total_cost = RF_BoW_false_negative_cost + RF_BoW_false_positive_cost\n",
    "\n",
    "print('The Random Forest model with Bag of Words features has', RF_BoW_false_negative, 'false negatives and', RF_BoW_false_positive,\n",
    "     'false positives. At a cost of 5 units per false negative and 100 units per false positive, this model costs the business', RF_BoW_total_cost,'units.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models with TF-IDF features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Naive Bayes model with TF-IDF features has 203 false negatives and 4 false positives. At a cost of 5 units per false negative and 100 units per false positive, this model costs the business 1415 units.\n"
     ]
    }
   ],
   "source": [
    "NB_tfidf_false_negative_cost = NB_tfidf_false_negative * false_negative_cost\n",
    "NB_tfidf_false_positive_cost = NB_tfidf_false_positive * false_positive_cost\n",
    "\n",
    "NB_tfidf_total_cost = NB_tfidf_false_negative_cost + NB_tfidf_false_positive_cost\n",
    "\n",
    "print('The Naive Bayes model with TF-IDF features has', NB_tfidf_false_negative, 'false negatives and', NB_tfidf_false_positive,\n",
    "     'false positives. At a cost of 5 units per false negative and 100 units per false positive, this model costs the business', NB_tfidf_total_cost,'units.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Decision Tree model with TF-IDF features has 42 false negatives and 37 false positives. At a cost of 5 units per false negative and 100 units per false positive, this model costs the business 3910 units.\n"
     ]
    }
   ],
   "source": [
    "DT_tfidf_false_negative_cost = DT_tfidf_false_negative * false_negative_cost\n",
    "DT_tfidf_false_positive_cost = DT_tfidf_false_positive * false_positive_cost\n",
    "\n",
    "DT_tfidf_total_cost = DT_tfidf_false_negative_cost + DT_tfidf_false_positive_cost\n",
    "\n",
    "print('The Decision Tree model with TF-IDF features has', DT_tfidf_false_negative, 'false negatives and', DT_tfidf_false_positive,\n",
    "     'false positives. At a cost of 5 units per false negative and 100 units per false positive, this model costs the business', DT_tfidf_total_cost,'units.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Random Forest model with TF-IDF features has 46 false negatives and 6 false positives. At a cost of 5 units per false negative and 100 units per false positive, this model costs the business 830 units.\n"
     ]
    }
   ],
   "source": [
    "RF_tfidf_false_negative_cost = RF_tfidf_false_negative * false_negative_cost\n",
    "RF_tfidf_false_positive_cost = RF_tfidf_false_positive * false_positive_cost\n",
    "\n",
    "RF_tfidf_total_cost = RF_tfidf_false_negative_cost + RF_tfidf_false_positive_cost\n",
    "\n",
    "print('The Random Forest model with TF-IDF features has', RF_tfidf_false_negative, 'false negatives and', RF_tfidf_false_positive,\n",
    "     'false positives. At a cost of 5 units per false negative and 100 units per false positive, this model costs the business', RF_tfidf_total_cost,'units.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models with Word2Vec Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Naive Bayes model with Word2Vec features has 102 false negatives and 45 false positives. At a cost of 5 units per false negative and 100 units per false positive, this model costs the business 5010 units.\n"
     ]
    }
   ],
   "source": [
    "NB_wv_false_negative_cost = NB_wv_false_negative * false_negative_cost\n",
    "NB_wv_false_positive_cost = NB_wv_false_positive * false_positive_cost\n",
    "\n",
    "NB_wv_total_cost = NB_wv_false_negative_cost + NB_wv_false_positive_cost\n",
    "\n",
    "print('The Naive Bayes model with Word2Vec features has', NB_wv_false_negative, 'false negatives and', NB_wv_false_positive,\n",
    "     'false positives. At a cost of 5 units per false negative and 100 units per false positive, this model costs the business', NB_wv_total_cost,'units.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Decision Tree model with Word2Vec features has 25 false negatives and 18 false positives. At a cost of 5 units per false negative and 100 units per false positive, this model costs the business 1925 units.\n"
     ]
    }
   ],
   "source": [
    "DT_wv_false_negative_cost = DT_wv_false_negative * false_negative_cost\n",
    "DT_wv_false_positive_cost = DT_wv_false_positive * false_positive_cost\n",
    "\n",
    "DT_wv_total_cost = DT_wv_false_negative_cost + DT_wv_false_positive_cost\n",
    "\n",
    "print('The Decision Tree model with Word2Vec features has', DT_wv_false_negative, 'false negatives and', DT_wv_false_positive,\n",
    "     'false positives. At a cost of 5 units per false negative and 100 units per false positive, this model costs the business', DT_wv_total_cost,'units.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Random Forest model with Word2Vec features has 15 false negatives and 9 false positives. At a cost of 5 units per false negative and 100 units per false positive, this model costs the business 975 units.\n"
     ]
    }
   ],
   "source": [
    "RF_wv_false_negative_cost = RF_wv_false_negative * false_negative_cost\n",
    "RF_wv_false_positive_cost = RF_wv_false_positive * false_positive_cost\n",
    "\n",
    "RF_wv_total_cost = RF_wv_false_negative_cost + RF_wv_false_positive_cost\n",
    "\n",
    "print('The Random Forest model with Word2Vec features has', RF_wv_false_negative, 'false negatives and', RF_wv_false_positive,\n",
    "     'false positives. At a cost of 5 units per false negative and 100 units per false positive, this model costs the business', RF_wv_total_cost,'units.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary table of costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Names</th>\n",
       "      <th>Costs to Business: Bag of Words Features</th>\n",
       "      <th>Costs to Business: TF-IDF Features</th>\n",
       "      <th>Costs to Business: Word2Vec Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>1250</td>\n",
       "      <td>1415</td>\n",
       "      <td>5010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>4700</td>\n",
       "      <td>3910</td>\n",
       "      <td>1925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>910</td>\n",
       "      <td>830</td>\n",
       "      <td>975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model Names  Costs to Business: Bag of Words Features  \\\n",
       "0    Naive Bayes                                      1250   \n",
       "1  Decision Tree                                      4700   \n",
       "2  Random Forest                                       910   \n",
       "\n",
       "   Costs to Business: TF-IDF Features  Costs to Business: Word2Vec Features  \n",
       "0                                1415                                  5010  \n",
       "1                                3910                                  1925  \n",
       "2                                 830                                   975  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names = ['Naive Bayes', 'Decision Tree', 'Random Forest']\n",
    "bag_of_words_costs = [NB_BoW_total_cost, DT_BoW_total_cost, RF_BoW_total_cost]\n",
    "tfidf_costs = [NB_tfidf_total_cost, DT_tfidf_total_cost, RF_tfidf_total_cost]\n",
    "word2vec_costs = [NB_wv_total_cost, DT_wv_total_cost, RF_wv_total_cost]\n",
    "\n",
    "table_data = ({'Model Names':model_names, 'Costs to Business: Bag of Words Features':bag_of_words_costs,\n",
    "              'Costs to Business: TF-IDF Features':tfidf_costs, 'Costs to Business: Word2Vec Features':word2vec_costs})\n",
    "\n",
    "costs_table = pd.DataFrame(table_data)\n",
    "\n",
    "costs_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
